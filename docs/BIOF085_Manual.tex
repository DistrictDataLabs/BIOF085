% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  letterpaper,
]{scrbook}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Alegreya}
  \setmonofont[]{Source Code Pro}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Introduction to Data Science using Python},
  pdfauthor={Abhijit Dasgupta, Ph.D.},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\title{Introduction to Data Science using Python}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{A Hands-On Guide}
\author{Abhijit Dasgupta, Ph.D.}
\date{Last updated: May 22, 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{part-introduction-and-python-basics}{%
\part{Introduction and Python Basics}\label{part-introduction-and-python-basics}}

\hypertarget{about-this-guide}{%
\chapter{About this guide}\label{about-this-guide}}

This guide will introduce you to different aspects of data science and
how they can be implemented using Python

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{this-guide-will-show-you-how-to}{%
\subsubsection*{This guide will show you how to}\label{this-guide-will-show-you-how-to}}
\addcontentsline{toc}{subsubsection}{This guide will show you how to}

\begin{itemize}
\tightlist
\item
\end{itemize}

\hypertarget{a-python-primer}{%
\chapter{A Python Primer}\label{a-python-primer}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Python is a popular, general purpose scripting language. The \href{https://www.tiobe.com/tiobe-index/}{TIOBE index} ranks Python as the third most popular programming language after C and Java, while this recent article in IEEE Computer Society says

\begin{quote}
``Python can be used for web and desktop applications, GUI-based desktop applications, machine learning, data science, and network servers. The programming language enjoys immense community support and offers several open-source libraries, frameworks, and modules that make application development a cakewalk.'' (\href{https://www.computer.org/publications/tech-news/trends/programming-languages-you-should-learn-in-2020}{Belani, 2020})
\end{quote}

\hypertarget{python-is-a-modular-language}{%
\subsection{Python is a modular language}\label{python-is-a-modular-language}}

Python is not a monolithic language but is comprised of a base programming language and numerous modules or libraries that add functionality to the language. Several of these libraries are installed with Python. The Anaconda Python Distribution adds more libraries that are useful for data science. Some libraries we will use include \texttt{numpy}, \texttt{pandas}, \texttt{seaborn}, \texttt{statsmodels} and \texttt{scikit-learn}. In the course of this workshop we will learn how to use Python libraries in your workflow.

\hypertarget{python-is-a-scripting-language}{%
\subsection{Python is a scripting language}\label{python-is-a-scripting-language}}

Using Python requires typing!! You write \emph{code} in Python that is then interpreted by the Python interpreter to make the computer implement your instructions. \textbf{Your code is like a recipe that you write for the computer}. Python is a \emph{high-level language} in that the code is English-like and human-readable and understandable, which reduces the time needed for a person to create the recipe. It is a language in that it has nouns (\emph{variables} or \emph{objects}), verbs (\emph{functions}) and a structure or grammar that allows the programmer to write recipes for different functionalities.

One thing that is important to note in Python: \textbf{case is important!}. If we have two objects named \texttt{data} and \texttt{Data}, they will refer to different things.

Scripting can be frustrating in the beginning. You will find that the code you wrote doesn't work ``for some reason'', though it looks like you wrote it fine. The first things I look for, in order, are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Did I spell all the variables and functions correctly
\item
  Did I close all the brackets I have opened
\item
  Did I finish all the quotes I started, and paired single- and double-quotes
\item
  Did I already import the right module for the function I'm trying to use.
\end{enumerate}

These may not make sense right now, but as we go into Python, I hope you will remember these to help debug your code.

\hypertarget{an-example}{%
\section{An example}\label{an-example}}

Let's consider the following piece of Python code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set a splitting point}
\NormalTok{split\_point }\OperatorTok{=} \DecValTok{3}

\CommentTok{\# make two empty lists}
\NormalTok{lower }\OperatorTok{=}\NormalTok{ []}\OperatorTok{;}\NormalTok{ upper }\OperatorTok{=}\NormalTok{ []}

\CommentTok{\# Split numbers from 0 to 9 into two groups, }
\CommentTok{\# one lower or equal to the split point and }
\CommentTok{\# one higher than the split point}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):  }\CommentTok{\# count from 0 to 9}
    \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ split\_point:}
\NormalTok{        lower.append(i)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        upper.append(i)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"lower:"}\NormalTok{, lower)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"upper:"}\NormalTok{, upper)}
\end{Highlighting}
\end{Shaded}

First note that any line (or part of a line) starting with \texttt{\#} is a \textbf{comment} in Python and is ignored by the interpreter. This makes it possible for us to write substantial text to remind us what each piece of our code does

The first piece of code that the Python interpreter actually reads is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{split\_point }\OperatorTok{=} \DecValTok{3}
\end{Highlighting}
\end{Shaded}

This takes the number 3 and stores it in the \textbf{variable} \texttt{split\_point}. Variables are just names where some Python object is stored. It really works as an address to some particular part of your computer's memory, telling the Python interpreter to look for the value stored at that particular part of memory. Variable names allow your code to be human-readable since it allows you to write expressive names to remind yourself what you are storing. The rules of variable names are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Variable names must start with a letter or underscore
\item
  The rest of the name can have letters, numbers or underscores
\item
  Names are case-sensitive
\end{enumerate}

The next piece of code initializes two \textbf{lists}, named \texttt{lower} and \texttt{upper}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lower }\OperatorTok{=}\NormalTok{ []}\OperatorTok{;}\NormalTok{ upper }\OperatorTok{=}\NormalTok{ []}
\end{Highlighting}
\end{Shaded}

The semi-colon tells Python that, even though written on the same line, a particular instruction ends at the semi-colon, then another piece of instruction is written.

Lists are a catch-all data structure that can store different kinds of things, In this case we'll use them to store numbers.

The next piece of code is a \textbf{for-loop} or a loop structure in Python.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):  }\CommentTok{\# count from 0 to 9}
    \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ split\_point:}
\NormalTok{        lower.append(i)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        upper.append(i)}
\end{Highlighting}
\end{Shaded}

It basically works like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  State with the numbers 0-9 (this is achieved in \texttt{range(10)})
\item
  Loop through each number, naming it \texttt{i} each time

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Computer programs allow you to over-write a variable with a new value
  \end{enumerate}
\item
  If the number currently stored in \texttt{i} is less than or equal to the value of \texttt{split\_point}, i.e., 3 then add it to the list \texttt{lower}. Otherwise add it to the list \texttt{upper}
\end{enumerate}

Note the indentation in the code. \textbf{This is not by accident}. Python understands the extent of a particular block of code within a for-loop (or within a \texttt{if} statement) using the indentations. In this segment there are 3 code blocks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The for-loop as a whole (1st indentation)
\item
  The \texttt{if} statement testing if the number is less than or equal to the split point, telling Python what to do if the test is true
\item
  The \texttt{else} statement stating what to do if the test in the \texttt{if} statement is false
\end{enumerate}

Every time a code block starts, the previous line ends in a colon (:). The code block ends when the indentation ends. We'll go into these elements in a bit.

The last bit of code prints out the results

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"lower:"}\NormalTok{, lower)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"upper:"}\NormalTok{, upper)}
\end{Highlighting}
\end{Shaded}

The \texttt{print} statement adds some text, and then prints out a representation of the object stored in the variable being printed. In this example, this is a list, and is printed as

\begin{verbatim}
lower: [0, 1, 2, 3]
upper: [4, 5, 6, 7, 8, 9]
\end{verbatim}

We will expand on these concepts in the next few sections.

\hypertarget{some-general-rules-on-python-syntax}{%
\subsection{Some general rules on Python syntax}\label{some-general-rules-on-python-syntax}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Comments are marked by \texttt{\#}
\item
  A statement is terminated by the end of a line, or by a \texttt{;}.
\item
  Indentation specifies blocks of code within particular structures. Whitespace at the beginning of lines matters. Typically you want to have 2 or 4 spaces to specify indentation, not a tab (\t) character. This can be set up in your IDE.
\item
  Whitespace within lines does not matter, so you can use spaces liberally to make your code more readable
\item
  Parentheses (\texttt{()}) are for grouping pieces of code or for calling functions.
\end{enumerate}

There are several conventions about code styling including the one in \href{https://www.python.org/dev/peps/pep-0008/\#function-and-variable-names}{PEP8} (PEP = Python Enhancement Proposal) and one proposed by \href{https://google.github.io/styleguide/pyguide.html\#316-naming}{Google}. We will typically be using lower case names, with words separated by underscores, in this workshop, basically following PEP8. Other conventions are of course allowed as long as they are within the basic rules stated above.

\hypertarget{data-types-in-python}{%
\section{Data types in Python}\label{data-types-in-python}}

We start with objects in Python. Objects can be of different types, including numbers (integers and floats), strings, arrays (vectors and matrices) and others. Any object can be assigned to a name, so that we can refer to the object in our code. We'll start with the basic types of objects.

\hypertarget{numeric-variables}{%
\subsection{Numeric variables}\label{numeric-variables}}

The following is a line of Python code, where we assign the value 1.2 to the variable \texttt{a}.

\begin{quote}
The act of assigning a name is done using the \texttt{=} sign. This is not equality in the mathematical sense, and has some non-mathematical behavior, as we'll see
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=} \FloatTok{1.2}
\end{Highlighting}
\end{Shaded}

This is an example of a \emph{floating-point number} or a decimal number, which in Python is called a \texttt{float}. We can verify this in Python itself.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

Floating point numbers can be entered either as decimals or in scientific notation

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \FloatTok{0.0005}
\NormalTok{y }\OperatorTok{=} \FloatTok{5e{-}4} \CommentTok{\# 5 x 10\^{}({-}4)}
\BuiltInTok{print}\NormalTok{(x }\OperatorTok{==}\NormalTok{ y)}
\end{Highlighting}
\end{Shaded}

You can also store integers in a variable. Integers are of course numbers, but can be stored more efficiently on your computer. They are stored as an \emph{integer} type, called \texttt{int}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OperatorTok{=} \DecValTok{23}
\BuiltInTok{type}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

These are the two primary numerical data types in Python. There are some others that we don't use as often, called \texttt{long} (for \emph{long integers}) and \texttt{complex} (for \emph{complex numbers})

\hypertarget{operations-on-numbers}{%
\subsubsection{Operations on numbers}\label{operations-on-numbers}}

There is an arithmetic and logic available to operate on elemental data types. For example, we do have addition, subtraction , multiplication and division available. For example, for numbers, we can do the following:

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
x + y & The sum of x and y\tabularnewline
x - y & The difference of x and y\tabularnewline
x * y & The product of x and y\tabularnewline
x / y & The quotient of x and y\tabularnewline
- x & The negative of x\tabularnewline
abs(x) & The absolute value of x\tabularnewline
x ** y & x raised to the power y\tabularnewline
int(x) & Convert a number to integer\tabularnewline
float(x) & Convert a number to floating point\tabularnewline
\bottomrule
\end{longtable}

Let's see some examples:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \DecValTok{5}
\NormalTok{y }\OperatorTok{=} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{+}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{{-}}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{*}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{/}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{**}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\hypertarget{strings}{%
\subsection{Strings}\label{strings}}

Strings are how text is represented within Python. It is always represented as a quoted object using either single (\texttt{\textquotesingle{}\textquotesingle{}}) or double (\texttt{""}) quotes, as long as the types of quotes are matched. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first\_name }\OperatorTok{=} \StringTok{"Abhijit"}
\NormalTok{last\_name }\OperatorTok{=} \StringTok{"Dasgupta"}
\end{Highlighting}
\end{Shaded}

The data type that these are stored in is \texttt{str}.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(first\_name)}
\end{Highlighting}
\end{Shaded}

\hypertarget{operations}{%
\subsubsection{Operations}\label{operations}}

Strings also have some ``arithmetic'' associated with it, which involves, essentially, concatenation and repetition. Let's start by considering two character variables that we've initialized.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=} \StringTok{"a"}
\NormalTok{b }\OperatorTok{=} \StringTok{"b"}
\end{Highlighting}
\end{Shaded}

Then we get the following operations and results

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
a + b & `ab'\tabularnewline
a * 5 & `aaaaa'\tabularnewline
\bottomrule
\end{longtable}

We can also see if a particular character or character string is part of an exemplar string

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{last\_name }\OperatorTok{=} \StringTok{"Dasgupta"}
\CommentTok{"gup"} \KeywordTok{in}\NormalTok{ last\_name}
\end{Highlighting}
\end{Shaded}

String manipulation is one of the strong suites of Python.
There are several \emph{functions} that apply to strings, that we will look at throughout the workshop, and especially when we look at string manipulation. In particular, there are built-in functions in base Python and powerful \emph{regular expression} capabilities in the \texttt{re} module.

\hypertarget{truthiness}{%
\subsection{Truthiness}\label{truthiness}}

Truthiness means evaluating the truth of a statement. This typically results in a Boolean object, which can take values \texttt{True} and \texttt{False}, but Python has several equivalent representations. The following values are considered the same as False:

\begin{quote}
\texttt{None}, \texttt{False}, zero (\texttt{0}, \texttt{0L}, \texttt{0.0}), any empty sequence (\texttt{{[}{]}}, \texttt{\textquotesingle{}\textquotesingle{}}, \texttt{()}), and a few others
\end{quote}

All other values are considered True. Usually we'll denote truth by \texttt{True} and the number \texttt{1}.

\hypertarget{operations-1}{%
\subsubsection{Operations}\label{operations-1}}

We will typically test for the truth of some comparisons. For example, if we have two numbers stored in \texttt{x} and \texttt{y}, then we can perform the following comparisons

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
x \textless{} y & x is strictly less than y\tabularnewline
x \textless= y & x is less than or equal to y\tabularnewline
x == y & x equals y (note, it's 2 = signs)\tabularnewline
x != y & x is not equal to y\tabularnewline
x \textgreater{} y & x is strictly greater than y\tabularnewline
x \textgreater= y & x is greater or equal to y\tabularnewline
\bottomrule
\end{longtable}

We can chain these comparisons using Boolean operations

\begin{longtable}[]{@{}ll@{}}
\toprule
Operation & Result\tabularnewline
\midrule
\endhead
x \textbar{} y & Either x is true or y is true or both\tabularnewline
x \& y & Both x and y are true\tabularnewline
not x & if x is true, then false, and vice versa\tabularnewline
\bottomrule
\end{longtable}

For example, if we have a number stored in \texttt{x}, and want to find out if it is between 3 and 7, we could write

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(x }\OperatorTok{\textgreater{}=} \DecValTok{3}\NormalTok{) }\OperatorTok{\&}\NormalTok{ (x }\OperatorTok{\textless{}=} \DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-note-about-variables-and-types}{%
\subsubsection{A note about variables and types}\label{a-note-about-variables-and-types}}

Some computer languages like C, C++ and Java require you to specify the type of data that will be held in a particular variable. For example,

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ x = }\DecValTok{4}\NormalTok{;}
\DataTypeTok{float}\NormalTok{ y = }\FloatTok{3.25}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

If you try later in the program to assign something of a different type to that variable, you will raise an error. For example, if I did, later in the program, \texttt{x\ =\ 3.95;}, that would be an error in C.

Python is \textbf{dynamically typed}, in that the same variable name can be assigned to different data types in different parts of the program, and the variable will simply be ``overwritten''. (This is not quite correct. What actually happens is that the variable name now ``points'' to a different part of the computer's memory where the new data is then stored in appropriate format). So the following is completely fine in Python:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \DecValTok{4}  \CommentTok{\# An int}
\NormalTok{x }\OperatorTok{=} \FloatTok{3.5}  \CommentTok{\# A float}
\NormalTok{x }\OperatorTok{=} \StringTok{"That\textquotesingle{}s my mother"}  \CommentTok{\# A str}
\NormalTok{x }\OperatorTok{=} \VariableTok{True}  \CommentTok{\# A bool}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Variables are like individual ingredients in your recipe. It's \emph{mis en place} or setting the table for any operations (\emph{functions}) we want to do to them. In a language context, variables are like \emph{nouns}, which will be acted on by verbs (\emph{functions}). In the next section we'll look at collections of variables. These collections are important in that it allows us to organize our variables with some structure.
\end{quote}

\hypertarget{data-structures-in-python}{%
\section{Data structures in Python}\label{data-structures-in-python}}

Python has several in-built data structures. We'll describe the three most used ones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lists (\texttt{{[}{]}})
\item
  Tuples (\texttt{()})
\item
  Dictionaries or dicts (\texttt{\{\}})
\end{enumerate}

Note that there are three different kinds of brackets being used.

Lists are baskets that can contain different kinds of things. They are ordered, so that there is a first element, and a second element, and a last element, in order. However, the \emph{kinds} of things in a single list doesn't have to be the same type.

Tuples are basically like lists, except that they are \emph{immutable}, i.e., once they are created, individual values can't be changed. They are also ordered, so there is a first element, a second element and so on.

Dictionaries are \textbf{unordered} key-value pairs, which are very fast for looking up things. They work almost like hash tables. Dictionaries will be very useful to us as we progress towards the PyData stack. Elements need to be referred to by \emph{key}, not by position.

\hypertarget{lists}{%
\subsection{Lists}\label{lists}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list }\OperatorTok{=}\NormalTok{ [}\StringTok{"apple"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\VariableTok{True}\NormalTok{, }\StringTok{"Harvey"}\NormalTok{, }\DecValTok{48205}\NormalTok{]}
\NormalTok{test\_list}
\end{Highlighting}
\end{Shaded}

There are various operations we can do on lists. First, we can determine the length (or size) of the list

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(test\_list)}
\end{Highlighting}
\end{Shaded}

The list is a catch-all, but we're usually interested in extracting elements from the list. This can be done by \emph{position}, since lists are \emph{ordered}. We can extract the 1\textsuperscript{st} element of the list using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Wait!! The index is 0?

Yup. Python is based deep underneath on the C language, where counting starts at 0. So the first element has index 0, second has index 1, and so on. So you need to be careful if you're used to counting from 1, or, if you're used to R, which does start counting at 1.
\end{quote}

We can also extract a set of consecutive elements from a list, which is often convenient. The typical form is to write the index as \texttt{a:b}. The (somewhat confusing) rule is that \texttt{a:b} means that you start at index \texttt{a}, but continue until \textbf{before index \texttt{b}}. So the notation \texttt{2:5} means include elements with index 2, 3, and 4. In the Python world, this is called \textbf{slicing}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\DecValTok{2}\NormalTok{:}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

If you want to start at the beginning or go to the end, there is a shortcut notation. The same rule holds, though. \texttt{:3} does \textbf{not} include the element at index 3, but \texttt{2:} \textbf{does} include the element at index 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\DecValTok{2}\NormalTok{:]}
\end{Highlighting}
\end{Shaded}

The important thing here is if you provide an index \texttt{a:b}, then \texttt{a} is include but \texttt{b} \textbf{is not}.

You can also count \textbf{backwards} from the end. The last element in a Python list has index \texttt{-1}.

\begin{longtable}[]{@{}llllll@{}}
\toprule
\endhead
index & 0 & 1 & 2 & 3 & 4\tabularnewline
element & `apple' & 3 & True & `Harvey' & 48205\tabularnewline
counting backwards & -5 & -4 & -3 & -2 & -1\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

You can also use negative indices to denote sequences within the list, with the same indexing rule applying. Note that you count from the last element (-1) and go backwards.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\OperatorTok{{-}}\DecValTok{3}\NormalTok{:]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\OperatorTok{{-}}\DecValTok{3}\NormalTok{:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

You can also make a list of lists, or nested lists

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nested\_list }\OperatorTok{=}\NormalTok{ [[}\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"b"}\NormalTok{], [}\DecValTok{3}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\DecValTok{4}\NormalTok{, }\StringTok{"d"}\NormalTok{]]}
\NormalTok{test\_nested\_list}
\end{Highlighting}
\end{Shaded}

This will come in useful when we talk about arrays and data frames.

You can also check if something is in the list, i.e.~is a member.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{"Harvey"} \KeywordTok{in}\NormalTok{ test\_list}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Lists have the following properties

\begin{itemize}
\tightlist
\item
  They can be heterogenous (each element can be a different type)
\item
  Lists can hold complex objects (lists, dicts, other objects) in addition to atomic objects (single numbers or words)
\item
  List have an ordering, so you can access list elements by position
\item
  List access can be done counting from the beginning or the end, and consecutive elements can be extracted using slices.
\end{itemize}
\end{quote}

\hypertarget{tuples}{%
\subsection{Tuples}\label{tuples}}

Tuples are like lists, except that once you create them, you can't change them.
This is why tuples are great if you want to store fixed parameters or entities
within your Python code, since they can't be over-written even by mistake. You
can extract elements of a tuple, but you can't over-write them. This is called
\emph{immutable}.

Note that, like lists, tuples can be heterogenous, which is also useful for coding purposes, as we will see.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_tuple }\OperatorTok{=}\NormalTok{ (}\StringTok{"apple"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\VariableTok{True}\NormalTok{, }\StringTok{"Harvey"}\NormalTok{, }\DecValTok{48205}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_tuple[:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list[}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \StringTok{"pear"}
\NormalTok{test\_list}
\end{Highlighting}
\end{Shaded}

See what happens in the next bit of code

\begin{verbatim}
test_tuple[0] = "pear"
test_tuple
\end{verbatim}

(I'm not running this since it gives an error)

\begin{quote}
Tuples are like lists, but once created, they cannot be changed. They are ordered and can be sliced.
\end{quote}

\hypertarget{dictionaries}{%
\subsection{Dictionaries}\label{dictionaries}}

Dictionaries, or \texttt{dict}, are collections of key-value pairs. Each element is referred to by \emph{key}, not by \emph{index}. In a dictionary, the keys can be strings, numbers or tuples, but the values can be any Python object. So you could have a dictionary where one value is a string, another is a number and a third is a DataFrame (essentially a data set, using the pandas library). A simple example might be an entry in a list of contacts

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"first\_name"}\NormalTok{: }\StringTok{"Abhijit"}\NormalTok{,}
    \StringTok{"last\_name"}\NormalTok{: }\StringTok{"Dasgupta"}\NormalTok{,}
    \StringTok{"Age"}\NormalTok{: }\DecValTok{48}\NormalTok{,}
    \StringTok{"address"}\NormalTok{: }\StringTok{"124 Main St"}\NormalTok{,}
    \StringTok{"Employed"}\NormalTok{: }\VariableTok{True}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note the special syntax. You separate the key-value pairs by colons (\texttt{:}), and each key-value pair is separated by commas. If you get a syntax error creating a dict, look at these first.

If you try to get the first name out using an index, you run into an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact[}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: 0
\end{verbatim}

You need to extract it by key

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact[}\StringTok{"first\_name"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

A dictionary is mutable, so you can change the value of any particular element

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact[}\StringTok{"address"}\NormalTok{] }\OperatorTok{=} \StringTok{"123 Main St"}
\NormalTok{contact[}\StringTok{"Employed"}\NormalTok{] }\OperatorTok{=} \VariableTok{False}
\NormalTok{contact}
\end{Highlighting}
\end{Shaded}

You can see all the keys and values in a dictionary using extractor functions

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact.keys()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{contact.values()}
\end{Highlighting}
\end{Shaded}

It turns out that dictionaries are really fast in terms of retrieving information, without having to count where an element it. So it is quite useful

We'll see that dictionaries are also one way to easily create pandas DataFrame objects on the fly.

There are a couple of other ways to create dict objects. One is using a list of tuples. Each key-value pair is represented by a tuple of length 2, where the 1st element is the key and the second element is the value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}first\_name\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Abhijit\textquotesingle{}}\NormalTok{),(}\StringTok{\textquotesingle{}last\_name\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Dasgupta\textquotesingle{}}\NormalTok{),(}\StringTok{\textquotesingle{}address\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}124 Main St\textquotesingle{}}\NormalTok{)]}
\BuiltInTok{dict}\NormalTok{(A)}
\end{Highlighting}
\end{Shaded}

This actually can be utilized to create a dict from a pair of lists. There is a really neat function, \texttt{zip}, that inputs several lists of the same length and creates a list of tuples, where the i-th element of each tuple comes from the i-th list, in order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}first\_name\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}last\_name\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}address\textquotesingle{}}\NormalTok{]}
\NormalTok{B }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Abhijit\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Dasgupta\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}124 Main St\textquotesingle{}}\NormalTok{]}
\BuiltInTok{dict}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(A, B))}
\end{Highlighting}
\end{Shaded}

\begin{quote}
The \texttt{zip} function is quite powerful in putting several lists together with corresponding elements of each list into a tuple
\end{quote}

On a side note, there is a function \texttt{defaultdict} from the \texttt{collections} module that is probably better to use. We'll come back to it when we talk about modules.

\hypertarget{operational-structures-in-python}{%
\section{Operational structures in Python}\label{operational-structures-in-python}}

\hypertarget{loops-and-list-comprehensions}{%
\subsection{Loops and list comprehensions}\label{loops-and-list-comprehensions}}

Loops are a basic construct in computer programming. The basic idea is that you have a recipe that you want to repeatedly run on different entities that you have created. The crude option would be to copy and paste your code several times, changing whatever inputs change across the entities. This is not only error-prone, but inefficient given that loops are a standard element of all programming languages.

You can create a list of these entities, and, using a loop, run your recipe on each entity automatically. For example, you have a data about votes in the presidential election from all 50 states, and you want to figure out what the percent voting for each major party is. So you could write this recipe in pseudocode as

\begin{verbatim}
Start with a list of datasets, one for each state
for each state
    compute and store fraction of votes that are Republican
    compute and store fraction of votes that are Democratic
\end{verbatim}

This is just English, but it can be translated easily into actual code. We'll attempt that at the end of this section.

The basic idea of a list is that there is a list of things you want to iterate over. You create a dummy variable as stand-in for each element of that list. Then you create a for-loop. This works like a conveyor belt and basket, so to speak. You line up elements of the list on the conveyor belt, and as you run the loop, one element of the list is ``scooped up'' and processed. Once that processing is done, the next element is ``scooped up'', and so forth. The dummy variable is essentially the basket (so the same basket (variable name) is re-used over and over until the conveyor belt (list) is empty).

In the examples below, we are showing a common use of for loops where we are enumerating the elements of a list as 0, 1, 2, \ldots{} using \texttt{range(len(test\_list))}. So the dummy variable \texttt{i} takes values 0, 1, 2, \ldots{} until the length of the list is reached. For each value of \texttt{i}, this for loop prints the i-th element of \texttt{test\_list}.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(test\_list)):}
    \BuiltInTok{print}\NormalTok{(test\_list[i])}
\end{Highlighting}
\end{Shaded}

Sometimes using the index number is easier to understand. However, we don't need to do this. We can just send the list itself into the for-loop (\texttt{u}) now is the dummy variable containing the actual element of \texttt{test\_list}. We'll get the same answer.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test\_list:}
    \BuiltInTok{print}\NormalTok{(u)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
The general structure for a \texttt{for} loop is:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (element) }\KeywordTok{in}\NormalTok{ (}\BuiltInTok{list}\NormalTok{):}
\NormalTok{      do some stuff}
\NormalTok{      do more stuff}
\end{Highlighting}
\end{Shaded}
\end{quote}

As a more practical example, let's try and sum a set of numbers using a for-loop (we'll see much better ways of doing this later)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_list2 }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{]}
\NormalTok{mysum }\OperatorTok{=} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test\_list2:}
\NormalTok{    mysum }\OperatorTok{=}\NormalTok{ mysum }\OperatorTok{+}\NormalTok{ u}
\BuiltInTok{print}\NormalTok{(mysum)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
There are two things to note here.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The code \texttt{mysum\ =\ mysum\ +\ u} is perfectly valid, once you realize that this isn't really math but an assignment or pointer to a location in memory. This code says that you find the current value stored in \texttt{mysum}, add the value of \texttt{u} to it, and then store it back into the storage that \texttt{mysum} points to
\item
  Indentation matters! Indent the last line and see what happens when you run this code
\end{enumerate}
\end{quote}

\hypertarget{a-little-deeper}{%
\subsubsection{A little deeper}\label{a-little-deeper}}

The entity to the right of the \texttt{in} in the for-loop can be an \textbf{iterator}, which is a generalization of a list. For example, we used \texttt{range(len(test\_list2))} above. If we just type

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

nothing really happens. This is an example of an iterator, which is only evaluated when it is called, rather than being stored in memory. This is useful especially when you iterate over large numbers of things, in terms of preserving memory and speed. To see the corresponding list, you would do

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

This \texttt{range} iterator is quite flexible:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{))  }\CommentTok{\# range from 5 to 10}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\CommentTok{\# range from 0 to 10 by 2}
\end{Highlighting}
\end{Shaded}

Note the rules here are very much like the slicing rules.

Other iterators that are often useful are the \texttt{enumerate} iterator and the \texttt{zip} iterator.

\texttt{enumerate} automatically creates both the index and the value for each element of a list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ i, val }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(L):}
    \BuiltInTok{print}\NormalTok{(i, val)}
\end{Highlighting}
\end{Shaded}

\texttt{zip} puts multiple lists together and creates a composite iterator. You can have any number of iterators in zip, and the length of the result is determined by the length of the shortest iterator. We introduced an example of \texttt{zip} as a way to create a \texttt{dict}.

\begin{quote}
Technically, \texttt{zip} can take multiple \emph{iterators} as inputs, not just lists
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first }\OperatorTok{=}\NormalTok{ [}\StringTok{"Han"}\NormalTok{, }\StringTok{"Luke"}\NormalTok{, }\StringTok{"Leia"}\NormalTok{, }\StringTok{"Anakin"}\NormalTok{]}
\NormalTok{last }\OperatorTok{=}\NormalTok{ [}\StringTok{"Solo"}\NormalTok{, }\StringTok{"Skywalker"}\NormalTok{, }\StringTok{"Skywaker"}\NormalTok{, }\StringTok{"Skywalker"}\NormalTok{]}
\NormalTok{types }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}light\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}light\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}light\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}light/dark/light\textquotesingle{}}\NormalTok{]}

\ControlFlowTok{for}\NormalTok{ val1, val2, val3 }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(first, last, types):}
    \BuiltInTok{print}\NormalTok{(val1, val2, }\StringTok{\textquotesingle{} : \textquotesingle{}}\NormalTok{, val3)}
\end{Highlighting}
\end{Shaded}

\hypertarget{controlling-loops}{%
\subsubsection{Controlling loops}\label{controlling-loops}}

There are two statements that can affect how loops run:

\begin{itemize}
\tightlist
\item
  The \texttt{break} statement breaks out of the loop
\item
  The \texttt{continue} statement skips the rest of the current loop and continues to the next element
\end{itemize}

For example

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{))}

\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
    \ControlFlowTok{if}\NormalTok{ u }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{: }\CommentTok{\# If u / 2 gives a remainder of 1}
        \ControlFlowTok{continue}
    \ControlFlowTok{if}\NormalTok{ u }\OperatorTok{\textgreater{}=} \DecValTok{8}\NormalTok{:}
        \ControlFlowTok{break}
    \BuiltInTok{print}\NormalTok{(u)}
\end{Highlighting}
\end{Shaded}

In this loop, we don't print the odd numbers, and we stop the loop once it gets to 8.

\hypertarget{list-comprehensions}{%
\subsection{List comprehensions}\label{list-comprehensions}}

List comprehensions are quick ways of generating a list from another list by using some recipe. For example, if we wanted to create a list of the squares of all the numbers in \texttt{test\_list2}, we could write

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{squares }\OperatorTok{=}\NormalTok{ [u }\OperatorTok{**} \DecValTok{2} \ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test\_list2]}
\NormalTok{squares}
\end{Highlighting}
\end{Shaded}

Similarly, if we wanted to find out what the types of each element of \texttt{test\_tuple} is, we could use

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{[}\BuiltInTok{type}\NormalTok{(u) }\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ test\_tuple]}
\end{Highlighting}
\end{Shaded}

\textbf{Exercise:} Can you use a list comprehension to find out the types of each element of the \texttt{contact} dict?

We can also use list comprehensions to extract arbitrary sets of elements of lists

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}g\textquotesingle{}}\NormalTok{]}
\NormalTok{test1 }\OperatorTok{=}\NormalTok{ [test[i] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ [}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{]]}
\NormalTok{test1}
\end{Highlighting}
\end{Shaded}

\hypertarget{conditional-evaluations}{%
\subsection{Conditional evaluations}\label{conditional-evaluations}}

The basic structure for conditional evaluation of code is an \textbf{if-then-else} structure.

\begin{verbatim}
if Condition 1 is true then
    do Recipe 1
else if (elif) Condition 2 is true then
  do Recipe 2
else
  do Recipe 3
\end{verbatim}

In Python, this is implemented as a \texttt{if-elif-else} structure. Let's take an example where we have a list of numbers, and we want to record whether the number is negative, odd, or even.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ [}\OperatorTok{{-}}\DecValTok{2}\NormalTok{, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{]}
\NormalTok{y }\OperatorTok{=}\NormalTok{ []  }\CommentTok{\# an empty list}

\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
    \ControlFlowTok{if}\NormalTok{ u }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{:}
\NormalTok{        y.append(}\StringTok{"Negative"}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ u }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{:  }\CommentTok{\# what is remainder when dividing by 2}
\NormalTok{        y.append(}\StringTok{"Odd"}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        y.append(}\StringTok{"Even"}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

Note here that the indentation (leading whitespace) is crucial to this structure. The \texttt{if-elif-else} structure is embedded in a for-loop, so the entire structure in indented. Also, each particular recipe is also indented within the if-elif-else structure.

\begin{quote}
The \texttt{elif} is optional, in that if you have only 2 conditions, then an \texttt{if-else} structure is sufficient. However, you can have multiple \texttt{elif}'s if you have more conditions. This kind of structure has to start with an \texttt{if}, end with an \texttt{else} and can have 0 or more \texttt{elif} in the middle.
\end{quote}

\hypertarget{functions}{%
\section{Functions}\label{functions}}

We've already seen some examples of \textbf{functions}, such as the \texttt{print()} function. For example, if we write \texttt{print(y)}, the function name is \texttt{print} and the functions \emph{argument} is \texttt{y}. So what are functions?

Functions are basically encapsulated recipes. They are groups of code that are given a name and can be called with 0 or more arguments. In a cookbook, you might have a recipe for pasta primavera. This is the name of a recipe that has ingredients and a method to cook. In Python, a similar recipe for the mean might be as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my\_mean(x):}
\NormalTok{    y }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
\NormalTok{        y }\OperatorTok{+=}\NormalTok{ u }
\NormalTok{    y }\OperatorTok{=}\NormalTok{ y }\OperatorTok{/} \BuiltInTok{len}\NormalTok{(x)}
    \ControlFlowTok{return}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

This takes a list of numbers \texttt{x}, loops over the elements of \texttt{x} to find their sum, and then divides by the length of \texttt{x} to compute the mean. It then returns this mean.

\begin{quote}
The notation \texttt{+=} is a shortcut often used in programming. The statement \texttt{y\ +=\ u} means, take the current value of \texttt{y}, add the value of \texttt{u} to it, and store it back in to \texttt{y}. This is a shorthand for \texttt{y\ =\ y\ +\ u}. In analogous fashion, you can use \texttt{-=}, \texttt{*=} and \texttt{/=} to do subtraction, multiplication and division respectively.
\end{quote}

A Python function must start with the keyword \texttt{def} followed by the name of the function, the arguments within parentheses, and then a colon. The actual code for the function is indented, just like in for-loops and if-elif-else structures. It ends with a \texttt{return} function which specifies the output of the function.

To use the \texttt{my\_mean} function,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{))}
\NormalTok{my\_mean(x)}
\end{Highlighting}
\end{Shaded}

\hypertarget{documenting-your-functions}{%
\subsection{Documenting your functions}\label{documenting-your-functions}}

Python has an in-built documentation system that allows you to readily document your functions using \emph{docstrings}. Basically, right after the first line with \texttt{def}, you can create a (multi-line) string that documents the function and will be printed if the help system is used for that function. You can create a multi-line string by \textbf{bounding it with 3 quotation marks on each side}. For example,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my\_mean(x):}
    \CommentTok{"""}
\CommentTok{  A function to compute the mean of a list of numbers.}
\CommentTok{  }
\CommentTok{  INPUTS:}
\CommentTok{  x : a list containing numbers}
\CommentTok{  }
\CommentTok{  OUTPUT:}
\CommentTok{  The arithmetic mean of the list of numbers}
\CommentTok{  """}
\NormalTok{    y }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ x:}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ y }\OperatorTok{+}\NormalTok{ u}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ y }\OperatorTok{/} \BuiltInTok{len}\NormalTok{(x)}
    \ControlFlowTok{return}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{help}\NormalTok{(my\_mean)}
\end{Highlighting}
\end{Shaded}

\hypertarget{modules-and-packages}{%
\section{Modules and Packages}\label{modules-and-packages}}

Python itself was built with the principle ``Batteries included'', in that it already comes with useful tools for a wide variety of tasks. On top of that, there is a large ecosystem of third-party tools and packages that can be added on to add more functionality. Almost all the data science functionality in Python comes from third-party packages.

\hypertarget{using-modules}{%
\subsection{Using modules}\label{using-modules}}

The Python standard library as well as third-party packages (which I'll use interchangeably with the term libraries) are structured as modules. In order to use a particular module you have to ``activate'' it in your Python session using the \texttt{import} statement.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\NormalTok{math.cos(math.pi)}
\end{Highlighting}
\end{Shaded}

In these statements, we have imported the \texttt{math} module. This module has many functions, one of which is the cosine or \texttt{cos} function. We use the notation \texttt{math.cos} to let Python know that we want to use the \texttt{cos} function that is in the \texttt{math} module. The value of \(\pi\) is also stored in the \texttt{math} module as \texttt{math.pi}, ie. the element \texttt{pi} within the moduel \texttt{math}.

Modules can often have long names, so Python caters to our laziness by allowing us to create aliases for modules when we import them. In this workshop we will use the following statements quite often

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\end{Highlighting}
\end{Shaded}

These statements import 3 modules into the current Python session, namely \texttt{numpy}, \texttt{pandas} and a submodule of the \texttt{matplotlib} module called \texttt{pyplot}. In each case, we have provided an alias to the module that is imported. So, in subsequent calls, we can just use the aliases.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.cos(np.pi)}
\end{Highlighting}
\end{Shaded}

If we only want some particular components of a module to be imported, we can specify them using the \texttt{from\ ...\ import\ ...} syntax. These imported components will not need the module specification when we subsequently use them.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ math }\ImportTok{import}\NormalTok{ pi, sin, cos}

\BuiltInTok{print}\NormalTok{(sin(pi))}
\BuiltInTok{print}\NormalTok{(cos(pi))}
\end{Highlighting}
\end{Shaded}

We had made reference to the \texttt{defaultdict} function from the \texttt{collections} module before. Using this instead of \texttt{dict} can be advantagous sometimes in data scientific work.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ defaultdict}

\NormalTok{A }\OperatorTok{=}\NormalTok{ defaultdict(}\BuiltInTok{list}\NormalTok{) }\CommentTok{\# Specify each component will be a list}
\NormalTok{B }\OperatorTok{=}\NormalTok{ \{\}}

\NormalTok{s }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}yellow\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{), (}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\DecValTok{2}\NormalTok{), (}\StringTok{\textquotesingle{}yellow\textquotesingle{}}\NormalTok{, }\DecValTok{3}\NormalTok{), (}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\DecValTok{4}\NormalTok{), (}\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{)]}
\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ s: }\CommentTok{\# k = key, v = value}
\NormalTok{    B[k].append(v)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: 'yellow'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ s:}
\NormalTok{    A[k].append(v)}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

The \texttt{defaultdict} sees a new key, and adds it to the dict, initializing it with an empty list (since we specified \texttt{defaultdict(list)}. The normal dict requires the key to already be in place in the dict for any operations to take place on that key-value pair. So the \texttt{default} dict is safer for on-the-fly work and when we don't know beforehand what keys we will encounter when storing data into the dict.

\begin{quote}
There is a temptation to use this method to import everything in a module so you don't have to specify the module. This is a \textbf{bad practice} generally, both because you clutter up the namespace that Python reads from, and because you may unknowingly over-write and replace a function from one module with one from another module, and you will have a hard time debugging your code.

The code you do \textbf{NOT} want to use is

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ math }\ImportTok{import} \OperatorTok{*}
\end{Highlighting}
\end{Shaded}
\end{quote}

\hypertarget{useful-modules-in-pythons-standard-library}{%
\subsection{Useful modules in Python's standard library}\label{useful-modules-in-pythons-standard-library}}

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright
Module\strut
\end{minipage} & \begin{minipage}[b]{0.72\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{os} and \texttt{sys}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Interfacing with the operating system, including files, directories, and executing shell commands\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{math} and \texttt{cmath}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Mathematical functions\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{itertools}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Constructing and using iterators\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{random}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
Generate random numbers\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright
\texttt{collections}\strut
\end{minipage} & \begin{minipage}[t]{0.72\columnwidth}\raggedright
More general collections for objects, beyond lists, tuples and dicts\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{installing-third-party-packageslibraries}{%
\subsection{Installing third-party packages/libraries}\label{installing-third-party-packageslibraries}}

The Anaconda Python distribution comes with its own installer and package manager called \texttt{conda}. The Anaconda repository contains most of the useful packages for data science, and many come pre-installed with the distribution. However, you can easily install packages using the \texttt{conda} manager.

\begin{verbatim}
conda install pandas
\end{verbatim}

would install the \texttt{pandas} package into your Python installation. If you wanted a particular version of this package, you could use

\begin{verbatim}
conda install pandas=0.23
\end{verbatim}

to install version 0.23 of the \texttt{pandas} package.

Anaconda also provides a repository for user-created packages. For example, to install the Python package RISE which I use for creating slides from Jupyter notebooks, I use

\begin{verbatim}
conda install -c conda-forge rise
\end{verbatim}

Sometimes you may find a Python package that is not part of the Anaconda repositories. Then you can use the more general Python program \texttt{pip} to install packages

\begin{verbatim}
pip install supersmoother
\end{verbatim}

This goes looking in the general Python package repository \href{https://pypi.org}{PyPi}, which you can also search on a web browser.

\hypertarget{environments}{%
\section{Environments}\label{environments}}

One of the nice things about Python is that you can set up environments for particular projects, that have all the packages you need for that project, without having to install those packages system-wide. This practice is highly recommended, since it creates a sandbox for you to play in for a project without contaminating the code from another project.

The Anaconda distribution and the \texttt{conda} program make this quite easy. There are a couple of ways of doing this.

\hypertarget{command-lineshell}{%
\subsection{Command-line/shell}\label{command-lineshell}}

You can open up a command line terminal (any terminal on Mac and Linux, the Anaconda Terminal in Windows) to create a new environment. For example, I have an environment I call \textbf{ds} that is my data science environment. This will include the packages \texttt{numpy}, \texttt{scipy}, \texttt{pandas},\texttt{matplotlib}, \texttt{seaborn},\texttt{statsmodels} and \texttt{scikit-learn} in it. The quick way to do this is

\begin{verbatim}
conda create -n ds numpy scipy pandas matplotlib seaborn statsmodels scikit-learn
\end{verbatim}

To use this environment, at the command line, type

\begin{verbatim}
conda activate ds
\end{verbatim}

Once you're done using it, at the command line, type

\begin{verbatim}
conda deactivate
\end{verbatim}

When your environment is activated, you'll see the name of the environment before the command prompt

\begin{figure}
\centering
\includegraphics{graphs/conda_env.png}
\caption{image-20200511003754816}
\end{figure}

\hypertarget{using-anaconda-navigator}{%
\subsection{Using Anaconda Navigator}\label{using-anaconda-navigator}}

Open the Anaconda Navigator from your start menu or using Spotlight on a Mac. Within the app is a section named ``Environments''

\begin{figure}
\centering
\includegraphics{graphs/AN_env_1.png}
\caption{image-20200511004048781}
\end{figure}

At the bottom of the 2\textsuperscript{nd} pane, you can see a ``Create'' button. Clicking it creates a pop-up window.

\begin{figure}
\centering
\includegraphics{graphs/AN_env_2.png}
\caption{image-20200511004259459}
\end{figure}

I've named this new environment \texttt{ds1} since I already have a \texttt{ds} environment. Click ``Create''. You'll have to wait a bit of time for the environment to be created. You can then add/install packages to this environment by clicking on packages on the right panel, making sure you changed the first drop-down menu from ``Installed'' to ``Not installed''.

\begin{figure}
\centering
\includegraphics{graphs/AN_env_3.png}
\caption{image-20200511004530076}
\end{figure}

Once you've selected the packages you want to install, click ``Appy'' on the bottom right of the window.

To activate an environment, you can go to the Home pane for Anaconda Navigator and change the environment on the ``Applications on'' drop-down menu.

\begin{figure}
\centering
\includegraphics{graphs/AN_env_4.png}
\caption{image-20200511004920105}
\end{figure}

\hypertarget{reproducing-environments}{%
\subsection{Reproducing environments}\label{reproducing-environments}}

Suppose you've got an environment set up the way you like it, and want to clone it on another machine that has Anaconda installed. There is an easy way to do this. You have to use the command line (Anaconda Prompt (Win) or a terminal) for this.

First activate the environment you want to export (I'll use \texttt{ds} as an example)

\begin{verbatim}
conda activate ds
\end{verbatim}

Then export the environment specifications which includes all the packages installed in that environment

\begin{verbatim}
conda env export > environment.yml
\end{verbatim}

You can take this \texttt{environment.yml} file to a new computer, or e-mail it to a collaborator to install the environment. This environment can be created on the new computer using

\begin{verbatim}
conda env create -f environment.yml
\end{verbatim}

where the first line of the \texttt{environment.yml} file creates the environment name.

You can also create the environment from an \texttt{environment.yml} file from Anaconda Navigator by using the Import button rather than the Create button in the instructions above.

\begin{quote}
If you are changing operating systems, create the \texttt{environment.yml} file using the command

\begin{verbatim}
conda env export --from-history > environment.yml
\end{verbatim}

This avoids potential issues with dependencies that may not be compatible across operating systems
\end{quote}

\hypertarget{seeking-help}{%
\section{Seeking help}\label{seeking-help}}

Most Python functions have some amount of documentation. As we saw when we created our own function, this documentation is part of the function definition. It can be accessed at the Python console in 2 ways:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{help}\NormalTok{(}\BuiltInTok{sum}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

or

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sum?}
\end{Highlighting}
\end{Shaded}

You can see the documentation of the \texttt{my\_sum} function we created earlier in this way, as well.

Other resources that are your friends in the internet age are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://stackoverflow.com}{Stack Overflow}: This is a Q \& A site. To find Python-related questions, use the tag \texttt{python}.
\item
  Google: Of course.
\item
  \href{https://stats.stackexchange.com}{Cross-Validated}: A data science oriented Q \& A site. Once again, use the tag \texttt{python}.
\end{enumerate}

\hypertarget{python-tools-for-data-science}{%
\chapter{Python tools for data science}\label{python-tools-for-data-science}}

(last updated 2020-05-18)

\hypertarget{the-pydata-stack}{%
\section{The PyData Stack}\label{the-pydata-stack}}

The Python Data Stack comprises a set of packages that makes Python a powerful data science language. These include

\begin{itemize}
\tightlist
\item
  Numpy: provides arrays and matrix algebra
\item
  Scipy: provides scientific computing capabilities
\item
  matplotlib: provides graphing capabilities
\end{itemize}

These were the original stack that was meant to replace Matlab. However, these were meant to tackle purely numerical data, and the kinds of heterogeneous data we regularly face needed more tools. These were added more recently.

\begin{itemize}
\tightlist
\item
  Pandas: provides data analytic structures like the data frame, as well as basic descriptive statistical capabilities
\item
  statsmodels: provides a fairly comprehensive set of statistical functions
\item
  scikit-learn: provides machine learning capabilities
\end{itemize}

This is the basic stack of packages we will be using in this workshop. Additionally we will use a few packages that add some functionality to the data science process. These include

\begin{itemize}
\item
  seaborn: Better statistical graphs
\item
  plotly: Interactive graphics
\item
  biopython: Python for bioinformatics
\end{itemize}

We may also introduce the package \texttt{rpy2} which allows one to run R from within Python. This can be useful since many bioinformatic pipelines are already implemented in R.

\begin{quote}
The \href{https://scipy.org}{PyData stack} also includes \texttt{sympy}, a symbolic mathematics package emulating Maple
\end{quote}

\hypertarget{numpy-numerical-and-scientific-computing}{%
\section{Numpy (numerical and scientific computing)}\label{numpy-numerical-and-scientific-computing}}

We start by importing the Numpy package into Python using the alias \texttt{np}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\end{Highlighting}
\end{Shaded}

Numpy provides both arrays (vectors, matrices, higher dimensional arrays) and vectorized functions which are very fast. Let's see how this works.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\FloatTok{9.3}\NormalTok{,}\FloatTok{10.6}\NormalTok{] }\CommentTok{\# This is a list}
\NormalTok{z\_array }\OperatorTok{=}\NormalTok{ np.array(z)}
\NormalTok{z\_array}
\end{Highlighting}
\end{Shaded}

Now, we have already seen functions in Python earlier. In Numpy, there are functions that are optimized for arrays, that can be accessed directly from the array objects. This is an example of \emph{object-oriented programming} in Python, where functions are provided for particular \emph{classes} of objects, and which can be directly accessed from the objects. We will use several such functions over the course of this workshop, but we won't actually talk about how to do this program development here.

\begin{quote}
Numpy functions are often very fast, and are \emph{vectorized}, i.e., they are written to work on vectors of numbers rather than single numbers. This is an advantage in data science since we often want to do the same operation to all elements of a column of data, which is essentially a vector
\end{quote}

We apply the functions \texttt{sum}, \texttt{min} (minimum value) and \texttt{max} (maximum value) to \texttt{z\_array}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_array.}\BuiltInTok{sum}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_array.}\BuiltInTok{min}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_array.}\BuiltInTok{max}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The versions of these functions in Numpy are optimized for arrays and are quite a bit faster than the corresponding functions available in base Python. When doing data work, these are the preferred functions.

These functions can also be used in the usual function manner:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{max}\NormalTok{(z\_array)}
\end{Highlighting}
\end{Shaded}

Calling \texttt{np.max} ensures that we are using the \texttt{max} function from numpy, and not the one in base Python.

\hypertarget{numpy-data-types}{%
\subsection{Numpy data types}\label{numpy-data-types}}

Numpy arrays are homogeneous in type.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{29}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

But, what if we provide a heterogeneous list?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{]}
\NormalTok{np.array(y)}
\end{Highlighting}
\end{Shaded}

So what's going on here? Upon conversion from a heterogeneous list, numpy converted the numbers into strings. This is necessary since, by definition, numpy arrays can hold data of a single type. When one of the elements is a string, numpy casts all the other entities into strings as well. Think about what would happen if the opposite rule was used. The string `a' doesn't have a corresponding number, while both numbers 1 and 3 have corresponding string representations, so going from string to numeric would create all sorts of problems.

\begin{quote}
The advantage of numpy arrays is that the data is stored in a contiguous section of memory, and you can be very efficient with homogeneous arrays in terms of manipulating them, applying functions, etc. However, \texttt{numpy} does provide a ``catch-all'' \texttt{dtype} called \texttt{object}, which can be any Python object. This \texttt{dtype} essentially is an array of pointers to actual data stored in different parts of the memory. You can get to the actual objects by extracting them. So one could do
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{], dtype}\OperatorTok{=}\StringTok{\textquotesingle{}object\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
which would basically be a valid \texttt{numpy} array, but would go back to the actual objects when used, much like a list. We can see this later if we want to transform a heterogeneous \texttt{pandas} \texttt{DataFrame} into a \texttt{numpy} array. It's not particularly useful as is, but it prevents errors from popping up during transformations from \texttt{pandas} to \texttt{numpy}.
\end{quote}

\hypertarget{generating-data-in-numpy}{%
\subsection{Generating data in numpy}\label{generating-data-in-numpy}}

We had seen earlier how we could generate a sequence of numbers in a list using \texttt{range}. In numpy, you can generate a sequence of numbers in an array using \texttt{arange} (which actually creates the array rather than provide an iterator like \texttt{range}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.arange(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can also generate regularly spaced sequences of numbers between particular values

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.linspace(start}\OperatorTok{=}\DecValTok{0}\NormalTok{, stop}\OperatorTok{=}\DecValTok{1}\NormalTok{, num}\OperatorTok{=}\DecValTok{11}\NormalTok{) }\CommentTok{\# or np.linspace(0, 1, 11)}
\end{Highlighting}
\end{Shaded}

You can also do this with real numbers rather than integers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.linspace(start }\OperatorTok{=} \DecValTok{0}\NormalTok{, stop }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{np.pi, num }\OperatorTok{=} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

More generally, you can transform lists into \texttt{numpy} arrays. We saw this above for vectors. For matrices, you can provide a list of lists. Note the double \texttt{{[}} in front and back.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array([[}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{],[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{7}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

You can generate an array of 0's

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.zeros(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This can easily be extended to a two-dimensional array (a matrix), by specifying the dimension of the matrix as a tuple.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.zeros((}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

You can also generate a matrix of 1s in a similar manner.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.ones((}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In matrix algebra, the identity matrix is important. It is a square matrix with 1's on the diagonal and 0's everywhere else.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.eye(}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can also create numpy vectors directly from lists, as long as lists are made up of atomic elements of the same type. This means a list of numbers or a list of strings. The elements can't be more composite structures, generally. One exception is a list of lists, where all the lists contain the same type of atomic data, which, as we will see, can be used to create a matrix or 2-dimensional array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{]}
\NormalTok{b }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}3\textquotesingle{}}\NormalTok{]}

\NormalTok{np.array(a)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.array(b)}
\end{Highlighting}
\end{Shaded}

\hypertarget{random-numbers}{%
\subsubsection{Random numbers}\label{random-numbers}}

Generating random numbers is quite useful in many areas of data science. All computers don't produce truly random numbers but generate \emph{pseudo-random} sequences. These are completely deterministic sequences defined algorithmically that emulate the properties of random numbers. Since these are deterministic, we can set a \emph{seed} or starting value for the sequence, so that we can exactly reproduce this sequence to help debug our code. To actually see how things behave in simulations we will often run several sequences of random numbers starting at different seed values.

The seed is set by the \texttt{RandomState} function within the \texttt{random} submodule of numpy. Note that all Python names are case-sensitive.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{35}\NormalTok{) }\CommentTok{\# set seed}
\NormalTok{rng.randint(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We have created a 3x4 matrix of random integers between 0 and 10 (in line with slicing rules, this includes 0 but not 10).

We can also create a random sample of numbers between 0 and 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng.random\_sample((}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We'll see later how to generate random numbers from particular probability distributions.

\hypertarget{vectors-and-matrices}{%
\subsection{Vectors and matrices}\label{vectors-and-matrices}}

Numpy generates arrays, which can be of arbitrary dimension. However the most useful are vectors (1-d arrays) and matrices (2-d arrays).

In these examples, we will generate samples from the Normal (Gaussian) distribution, with mean 0 and variance 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We can compute some characteristics of this matrix's dimensions. The number of rows and columns are given by \texttt{shape}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.shape}
\end{Highlighting}
\end{Shaded}

The total number of elements are given by \texttt{size}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.size}
\end{Highlighting}
\end{Shaded}

If we want to create a matrix of 0's with the same dimensions as \texttt{A}, we don't actually have to compute its dimensions. We can use the \texttt{zeros\_like} function to figure it out.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.zeros\_like(A)}
\end{Highlighting}
\end{Shaded}

We can also create vectors by only providing the number of rows to the random sampling function. The number of columns will be assumed to be 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{,))}
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\hypertarget{extracting-elements-from-arrays}{%
\subsubsection{Extracting elements from arrays}\label{extracting-elements-from-arrays}}

The syntax for extracting elements from arrays is almost exactly the same as for lists, with the same rules for slices.

\textbf{Exercise:} State what elements of B are extracted by each of the following statements

\begin{verbatim}
B[:3]
B[:-1]
B[[0,2,4]]
B[[0,2,5]]
\end{verbatim}

For matrices, we have two dimensions, so you can slice by rows, or columns or both.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

We can extract the first column by specifying \texttt{:} (meaning everything) for the rows, and the index for the column (reminder, Python starts counting at 0)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[:,}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Similarly the 4th row can be extracted by putting the row index, and \texttt{:} for the column index.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[}\DecValTok{3}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

All slicing operations work for rows and columns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[:}\DecValTok{2}\NormalTok{,:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{array-operations}{%
\subsubsection{Array operations}\label{array-operations}}

We can do a variety of vector and matrix operations in \texttt{numpy}.

First, all usual arithmetic operations work on arrays, like adding or multiplying an array with a scalar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.randn(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{+} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

We can also add and multiply arrays \textbf{element-wise} as long as they are the same shape.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{+}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{*}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

You can also do \textbf{matrix multiplication}. Recall what this is.

If you have a matrix \(A_{m x n}\) and another matrix \(B_{n x p}\), as long as the number of columns of \(A\) and rows of \(B\) are the same, you can multiply them (\(C_{m x p} = A_{m x n}B_{n x p}\)), with the (i,j)-th element of C being

\[ c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}, i= 1, \dots, m; j = 1, \dots, p\]

In \texttt{numpy} the operant for matrix multiplication is \texttt{@}.

In the above examples, \texttt{A} and \texttt{B} cannot be multiplied since they have incompatible dimensions. However, we can take the \emph{transpose} of \texttt{B}, i.e.~flip the rows and columns, to make it compatible with \texttt{A} for matrix multiplication.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{@}\NormalTok{ np.transpose(B)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.transpose(A) }\OperatorTok{@}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

More generally, you can \emph{reshape} a \texttt{numpy} array into a new shape, provided it is compatible with the number of elements in the original array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\NormalTok{D}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D.reshape(}\DecValTok{8}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D.reshape(}\DecValTok{1}\NormalTok{,}\DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This can also be used to cast a vector into a matrix.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{20}\NormalTok{)}
\NormalTok{E }\OperatorTok{=}\NormalTok{ e.reshape(}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\NormalTok{E}
\end{Highlighting}
\end{Shaded}

\begin{quote}
One thing to note in all the reshaping operations above is that the new array takes elements of the old array \textbf{by row}. See the examples above to convince yourself of that.
\end{quote}

\hypertarget{statistical-operations-on-arrays}{%
\subsubsection{Statistical operations on arrays}\label{statistical-operations-on-arrays}}

You can sum all the elements of a matrix using \texttt{sum}. You can also sum along rows or along columns by adding an argument to the \texttt{sum} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{sum}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

You can sum along rows (i.e., down columns) with the option \texttt{axis\ =\ 0}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can sum along columns (i.e., across rows) with \texttt{axis\ =\ 1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Of course, you can use the usual function calls: \texttt{np.sum(A,\ axis\ =\ 1)}
\end{quote}

We can also find the minimum and maximum values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{min}\NormalTok{(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.}\BuiltInTok{max}\NormalTok{(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can also find the \textbf{position} where the minimum and maximum values occur.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.argmin(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.argmax(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can sort arrays and also find the indices which will result in the sorted array. I'll demonstrate this for a vector, where it is more relevant

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.sort(a)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.argsort(a)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[np.argsort(a)]}
\end{Highlighting}
\end{Shaded}

\texttt{np.argsort} can also help you find the 2nd smallest or 3rd largest value in an array, too.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind\_2nd\_smallest }\OperatorTok{=}\NormalTok{ np.argsort(a)[}\DecValTok{1}\NormalTok{]}
\NormalTok{a[ind\_2nd\_smallest]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind\_3rd\_largest }\OperatorTok{=}\NormalTok{ np.argsort(a)[}\OperatorTok{{-}}\DecValTok{3}\NormalTok{]}
\NormalTok{a[ind\_3rd\_largest]}
\end{Highlighting}
\end{Shaded}

You can also sort strings in this way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OperatorTok{=}\NormalTok{ np.array([}\StringTok{\textquotesingle{}Aram\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Raymond\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Elizabeth\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Donald\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Harold\textquotesingle{}}\NormalTok{])}
\NormalTok{np.sort(m)}
\end{Highlighting}
\end{Shaded}

If you want to sort arrays \textbf{in place}, you can use the \texttt{sort} function in a different way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m.sort()}
\NormalTok{m}
\end{Highlighting}
\end{Shaded}

\hypertarget{putting-arrays-together}{%
\subsubsection{Putting arrays together}\label{putting-arrays-together}}

We can put arrays together by row or column, provided the corresponding axes have compatible lengths.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}A = \textquotesingle{}}\NormalTok{, A)}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}B = \textquotesingle{}}\NormalTok{, B)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.hstack((A,B))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.vstack((A,B))}
\end{Highlighting}
\end{Shaded}

Note that both \texttt{hstack} and \texttt{vstack} take a \textbf{tuple} of arrays as input.

\hypertarget{logicalboolean-operations}{%
\subsubsection{Logical/Boolean operations}\label{logicalboolean-operations}}

You can query a matrix to see which elements meet some criterion. In this example, we'll see which elements are negative.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{\textless{}} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

This is called \textbf{masking}, and is useful in many contexts.

We can extract all the negative elements of A using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[A}\OperatorTok{\textless{}}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

This forms a 1-d array. You can also count the number of elements that meet the criterion

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{sum}\NormalTok{(A}\OperatorTok{\textless{}}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Since the entity \texttt{A\textless{}0} is a matrix as well, we can do row-wise and column-wise operations as well.

\hypertarget{beware-of-copies}{%
\subsection{Beware of copies}\label{beware-of-copies}}

One has to be a bit careful with copying objects in Python. By default, if you just assign one object to a new name, it does a \emph{shallow copy}, which means that both names point to the same memory. So if you change something in the original, it also changes in the new copy.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[}\DecValTok{0}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A1 }\OperatorTok{=}\NormalTok{ A}
\NormalTok{A1[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{4}
\NormalTok{A[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

To actually create a copy that is not linked back to the original, you have to make a \emph{deep copy}, which creates a new space in memory and a new pointer, and copies the original object to the new memory location

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A1 }\OperatorTok{=}\NormalTok{ A.copy()}
\NormalTok{A1[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{6}
\NormalTok{A[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

You can also replace sub-matrices of a matrix with new data, provided that the dimensions are compatible. (Make sure that the sub-matrix we are replacing below truly has 2 rows and 2 columns, which is what \texttt{np.eye(2)} will produce)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[:}\DecValTok{2}\NormalTok{,:}\DecValTok{2}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.eye(}\DecValTok{2}\NormalTok{)}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\hypertarget{reducing-matrix-dimensions}{%
\subsubsection{Reducing matrix dimensions}\label{reducing-matrix-dimensions}}

Sometimes the output of some operation ends up being a matrix of one column or one row. We can reduce it to become a vector. There are two functions that can do that, \texttt{flatten} and \texttt{ravel}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{, (}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\NormalTok{A}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.flatten()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.ravel()}
\end{Highlighting}
\end{Shaded}

So why two functions? I'm not sure, but they do different things behind the scenes. \texttt{flatten} creates a \textbf{copy}, i.e.~a new array disconnected from \texttt{A}. \texttt{ravel} creates a \textbf{view}, so a representation of the original array. If you then changed a value after a \texttt{ravel} operation, you would also change it in the original array; if you did this after a \texttt{flatten} operation, you would not.

\hypertarget{broadcasting-in-python}{%
\subsection{Broadcasting in Python}\label{broadcasting-in-python}}

Python deals with arrays in an interesting way, in terms of matching up dimensions of arrays for arithmetic operations. There are 3 rules:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If two arrays differ in the number of dimensions, the shape of the smaller array is padded with 1s on its \emph{left} side
\item
  If the shape doesn't match in any dimension, the array with shape = 1 in that dimension is stretched to match the others' shape
\item
  If in any dimension the sizes disagree and none of the sizes are 1, then an error is generated
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{B }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A.shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B.shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{{-}}\NormalTok{ B}
\end{Highlighting}
\end{Shaded}

B is 1-d, A is 2-d, so B's shape is made into (1,5) (added to the left). Then it is repeated into 4 rows to make it's shape (4,5), then the operation is performed. This means that we subtract the first element of B from the first column of A, the second element of B from the second column of A, and so on.

You can be explicit about adding dimensions for broadcasting by using \texttt{np.newaxis}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B[np.newaxis,:].shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B[:,np.newaxis].shape}
\end{Highlighting}
\end{Shaded}

\hypertarget{an-example-optional-intermediateadvanced}{%
\subsubsection{An example (optional, intermediate/advanced))}\label{an-example-optional-intermediateadvanced}}

This can be very useful, since these operations are faster than for loops. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OperatorTok{=}\NormalTok{ rng.random\_sample((}\DecValTok{10}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{d}
\end{Highlighting}
\end{Shaded}

We want to find the Euclidean distance (the sum of squared differences) between the points defined by the rows. This should result in a 10x10 distance matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d.shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[np.newaxis,:,:]}
\end{Highlighting}
\end{Shaded}

creates a 3-d array with the first dimension being of length 1

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[np.newaxis,:,:].shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[:, np.newaxis,:]}
\end{Highlighting}
\end{Shaded}

creates a 3-d array with the 2nd dimension being of length 1

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d[:,np.newaxis,:].shape}
\end{Highlighting}
\end{Shaded}

Now for the trick, using broadcasting of arrays. These two arrays are incompatible without broadcasting, but with broadcasting, the right things get repeated to make things compatible

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{((d[:,np.newaxis,:] }\OperatorTok{{-}}\NormalTok{ d[np.newaxis,:,:]) }\OperatorTok{**} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq.shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq}
\end{Highlighting}
\end{Shaded}

Whoops! we wanted a 10x10 matrix, not a scalar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(d[:,np.newaxis,:] }\OperatorTok{{-}}\NormalTok{ d[np.newaxis,:,:]).shape}
\end{Highlighting}
\end{Shaded}

What we really want is the 10x10 distance matrix.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{((d[:,np.newaxis,:] }\OperatorTok{{-}}\NormalTok{ d[np.newaxis,:,:]) }\OperatorTok{**} \DecValTok{2}\NormalTok{, axis}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can verify what is happening by creating \texttt{D\ =\ d{[}:,np.newaxis,:{]}-d{[}np.newaxis,:,:{]}} and then looking at \texttt{D{[}:,:,0{]}} and \texttt{D{[}:,:,1{]}}. These are the difference between each combination in the first and second columns of d, respectively. Squaring and summing along the 3rd axis then gives the sum of squared differences.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq.shape}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist\_sq.diagonal()}
\end{Highlighting}
\end{Shaded}

\hypertarget{conclusions-moving-forward}{%
\subsection{Conclusions moving forward}\label{conclusions-moving-forward}}

It's important to understand numpy and arrays, since most data sets we encounter are rectangular. The notations and operations we saw in numpy will translate to data, except for the fact that data is typically heterogeneous, i.e., of different types. The problem with using numpy for modern data analysis is that if you have mixed data types, it will all be coerced to strings, and then you can't actually do any data analysis.

The solution to this issue (which is also present in Matlab) came about with the \texttt{pandas} package, which is the main workhorse of data science in Python

\hypertarget{pandas}{%
\chapter{Pandas}\label{pandas}}

(last updated 2020-05-18 10:19:20)

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

\texttt{pandas} is the Python Data Analysis package. It allows for data ingestion, transformation and cleaning, and creates objects that can then be passed on to analytic packages like \texttt{statsmodels} and \texttt{scikit-learn} for modeling and packages like \texttt{matplotlib}, \texttt{seaborn}, and \texttt{plotly} for visualization.

\texttt{pandas} is built on top of numpy, so many numpy functions are commonly used in manipulating \texttt{pandas} objects.

\begin{quote}
\texttt{pandas} is a pretty extensive package, and we'll only be able to cover some of its features. For more details, there is free online documentation at \href{https://pandas.pydata.org}{pandas.pydata.org}. You can also look at the book \href{https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython-dp-1491957662/dp/1491957662/}{``Python for Data Analysis (2nd edition)''} by Wes McKinney, the original developer of the pandas package, for more details.
\end{quote}

\hypertarget{starting-pandas}{%
\section{Starting pandas}\label{starting-pandas}}

As with any Python module, you have to ``activate'' \texttt{pandas} by using \texttt{import}. The ``standard'' alias for \texttt{pandas} is \texttt{pd}. We will also import \texttt{numpy}, since \texttt{pandas} uses some \texttt{numpy} functions in the workflows.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-import-and-export}{%
\section{Data import and export}\label{data-import-and-export}}

Most data sets you will work with are set up in tables, so are rectangular in shape. Think Excel spreadsheets. In \texttt{pandas} the structure that will hold this kind of data is a \texttt{DataFrame}. We can read external data into a \texttt{DataFrame} using one of many \texttt{read\_*} functions. We can also write from a \texttt{DataFrame} to a variety of formats using \texttt{to\_*} functions. The most common of these are listed below:

\begin{longtable}[]{@{}llll@{}}
\toprule
Format type & Description & reader & writer\tabularnewline
\midrule
\endhead
text & CSV & read\_csv & to\_csv\tabularnewline
& Excel & read\_excel & to\_excel\tabularnewline
text & JSON & read\_json & to\_json\tabularnewline
binary & Feather & read\_feather & to\_feather\tabularnewline
binary & SAS & read\_sas &\tabularnewline
SQL & SQL & read\_sql & to\_sql\tabularnewline
\bottomrule
\end{longtable}

We'll start by reading in the \texttt{mtcars} dataset stored as a CSV file

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.read\_csv(}\StringTok{\textquotesingle{}data/mtcars.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This just prints out the data, but then it's lost. To use this data, we have to give it a name, so it's stored in Python's memory

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/mtcars.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
One of the big differences between a spreadsheet program and a programming language from the data science perspective is that you have to load data into the programming language. It's not ``just there'' like Excel. This is a good thing, since it allows the common functionality of the programming language to work across multiple data sets, and also keeps the original data set pristine. Excel users can run into problems and \href{https://nature.berkeley.edu/garbelottoat/?p=1488}{corrupt their data} if they are not careful.
\end{quote}

If we wanted to write this data set back out into an Excel file, say, we could do

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.to\_excel(}\StringTok{\textquotesingle{}data/mtcars.xlsx\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
You may get an error if you don't have the \texttt{openpyxl} package installed. You can easily install it from the Anaconda prompt using \texttt{conda\ install\ openpyxl} and following the prompts.
\end{quote}

\hypertarget{exploring-a-data-set}{%
\section{Exploring a data set}\label{exploring-a-data-set}}

We would like to get some idea about this data set. There are a bunch of functions linked to the \texttt{DataFrame} object that help us in this. First we will use \texttt{head} to see the first 8 rows of this data set

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.head(}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is our first look into this data. We notice a few things. Each column has a name, and each row has an \emph{index}, starting at 0.

\begin{quote}
If you're interested in the last N rows, there is a corresponding \texttt{tail} function
\end{quote}

Let's look at the data types of each of the columns

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.dtypes}
\end{Highlighting}
\end{Shaded}

This tells us that some of the variables, like \texttt{mpg} and \texttt{disp}, are floating point (decimal) numbers, several are integers, and \texttt{make} is an ``object''. The \texttt{dtypes} function borrows from \texttt{numpy}, where there isn't really a type for character or categorical variables. So most often, when you see ``object'' in the output of \texttt{dtypes}, you think it's a character or categorical variable.

We can also look at the data structure in a bit more detail.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.info()}
\end{Highlighting}
\end{Shaded}

This tells us that this is indeed a \texttt{DataFrame}, wth 12 columns, each with 32 valid observations. Each row has an index value ranging from 0 to 11. We also get the approximate size of this object in memory.

You can also quickly find the number of rows and columns of a data set by using \texttt{shape}, which is borrowed from numpy.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.shape}
\end{Highlighting}
\end{Shaded}

More generally, we can get a summary of each variable using the \texttt{describe} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.describe()}
\end{Highlighting}
\end{Shaded}

These are usually the first steps in exploring the data.

\hypertarget{data-structures-and-types}{%
\section{Data structures and types}\label{data-structures-and-types}}

pandas has two main data types: \texttt{Series} and \texttt{DataFrame}. These are analogous to vectors and matrices, in that a \texttt{Series} is 1-dimensional while a \texttt{DataFrame} is 2-dimensional.

\hypertarget{pandas.series}{%
\subsection{pandas.Series}\label{pandas.series}}

The \texttt{Series} object holds data from a single input variable, and is required, much like numpy arrays, to be homogeneous in type. You can create \texttt{Series} objects from lists or numpy arrays quite easily

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OperatorTok{=}\NormalTok{ pd.Series([}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,np.nan, }\DecValTok{9}\NormalTok{, }\DecValTok{13}\NormalTok{])}
\NormalTok{s}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2 }\OperatorTok{=}\NormalTok{ pd.Series(np.arange(}\DecValTok{1}\NormalTok{,}\DecValTok{20}\NormalTok{))}
\NormalTok{s2}
\end{Highlighting}
\end{Shaded}

You can access elements of a \texttt{Series} much like a \texttt{dict}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2[}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

There is no requirement that the index of a \texttt{Series} has to be numeric. It can be any kind of scalar object

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3 }\OperatorTok{=}\NormalTok{ pd.Series(np.random.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, (}\DecValTok{5}\NormalTok{,)), index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{])}
\NormalTok{s3}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3[}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3[}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Well, slicing worked, but it gave us something different than expected. It gave us both the start \textbf{and} end of the slice, which is unlike what we've encountered so far!!

It turns out that in \texttt{pandas}, slicing by index actually does this. It is a discrepancy from \texttt{numpy} and Python in general that we have to be careful about.

You can extract the actual values into a numpy array

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3.to\_numpy()}
\end{Highlighting}
\end{Shaded}

In fact, you'll see that much of \texttt{pandas}' structures are build on top of \texttt{numpy} arrays. This is a good thing, since you can take advantage of the powerful numpy functions that are built for fast, efficient scientific computing.

Making the point about slicing again,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s3.to\_numpy()[}\DecValTok{0}\NormalTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

This is different from index-based slicing done earlier.

\hypertarget{pandas.dataframe}{%
\subsection{pandas.DataFrame}\label{pandas.dataframe}}

The \texttt{DataFrame} object holds a rectangular data set. Each column of a \texttt{DataFrame} is a \texttt{Series} object. This means that each column of a \texttt{DataFrame} must be comprised of data of the same type, but different columns can hold data of different types. This structure is extremely useful in practical data science. The invention of this structure was, in my opinion, transformative in making Python an effective data science tool.

\hypertarget{creating-a-dataframe}{%
\subsubsection{Creating a DataFrame}\label{creating-a-dataframe}}

The \texttt{DataFrame} can be created by importing data, as we saw in the previous section. It can also be created by a few methods within Python.

First, it can be created from a 2-dimensional \texttt{numpy} array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{25}\NormalTok{)}
\NormalTok{d1 }\OperatorTok{=}\NormalTok{ pd.DataFrame(rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)))}
\NormalTok{d1}
\end{Highlighting}
\end{Shaded}

You will notice that it creates default column names, that are merely the column number, starting from 0. We can also create the column names and row index (similar to the \texttt{Series} index we saw earlier) directly during creation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2 }\OperatorTok{=}\NormalTok{ pd.DataFrame(rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, (}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)), }
\NormalTok{                  columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{], }
\NormalTok{                  index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{])}
\NormalTok{d2}
\end{Highlighting}
\end{Shaded}

\begin{quote}
We could also create a \texttt{DataFrame} from a list of lists, as long as things line up, just as we showed for \texttt{numpy} arrays. However, to me, other ways, including the \texttt{dict} method below, make more sense.
\end{quote}

We can change the column names (which can be extracted and replaced with the \texttt{columns} attribute) and the index values (using the \texttt{index} attribute).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2.columns}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2.columns }\OperatorTok{=}\NormalTok{ pd.Index([}\StringTok{\textquotesingle{}V\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{)]) }\CommentTok{\# Index creates the right objects for both column names and row names, which can be extracted and changed with the \textasciigrave{}index\textasciigrave{} attribute}
\NormalTok{d2}
\end{Highlighting}
\end{Shaded}

\textbf{Exercise:} Can you explain what I did in the list comprehension above? The key points are understanding \texttt{str} and how I constructed the \texttt{range}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2.index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}o1\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}o2\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}o3\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}o4\textquotesingle{}}\NormalTok{]}
\NormalTok{d2}
\end{Highlighting}
\end{Shaded}

You can also extract data from a homogeneous \texttt{DataFrame} to a \texttt{numpy} array

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d1.to\_numpy()}
\end{Highlighting}
\end{Shaded}

\begin{quote}
It turns out that you can use \texttt{to\_numpy} for a non-homogeneous \texttt{DataFrame} as well. \texttt{numpy} just makes it homogeneous by assigning each column the data type \texttt{object}. This also limits what you can do in \texttt{numpy} with the array and may require changing data types using the \href{https://numpy.org/devdocs/reference/generated/numpy.ndarray.astype.html}{\texttt{astype} function}. There is some more detail about the \texttt{object} data type in the Python Tools for Data Science (\href{01_python_tools_ds.ipynb\#object}{notebook}, \href{01_python_tools_ds.pdf}{PDF}) document.
\end{quote}

The other easy way to create a \texttt{DataFrame} is from a \texttt{dict} object, where each component object is either a list or a numpy array, and is homogeneous in type. One exception is if a component is of size 1; then it is repeated to meet the needs of the \texttt{DataFrame}'s dimensions

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{:}\FloatTok{3.}\NormalTok{,}
    \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{:rng.random\_sample(}\DecValTok{5}\NormalTok{),}
    \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: pd.Timestamp(}\StringTok{\textquotesingle{}20200512\textquotesingle{}}\NormalTok{),}
    \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{: np.array([}\DecValTok{6}\NormalTok{] }\OperatorTok{*} \DecValTok{5}\NormalTok{),}
    \StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{: pd.Categorical([}\StringTok{\textquotesingle{}yes\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}no\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}no\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}yes\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}no\textquotesingle{}}\NormalTok{]),}
    \StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}NIH\textquotesingle{}}\NormalTok{\})}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.info()}
\end{Highlighting}
\end{Shaded}

We note that C is a date object, E is a category object, and F is a text/string object. pandas has excellent time series capabilities (having origins in FinTech), and the \texttt{TimeStamp} function creates datetime objects which can be queried and manipulated in Python. We'll describe category data in the next section.

You can also create a \texttt{DataFrame} where each column is composed of composite objects, like lists and dicts, as well. This might have limited value in some settings, but may be useful in others. In particular, this allows capabilities like the \href{https://jennybc.github.io/purrr-tutorial/ls13_list-columns.html}{\emph{list-column} construct in R tibbles}. For example,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.DataFrame(\{}\StringTok{\textquotesingle{}list\textquotesingle{}}\NormalTok{ :[[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{],[}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{],[}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{]],}
             \StringTok{\textquotesingle{}tuple\textquotesingle{}}\NormalTok{ : [(}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{)],}
              \StringTok{\textquotesingle{}set\textquotesingle{}}\NormalTok{ : [\{}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{\}, \{}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{\}, \{}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{\}], }
            \StringTok{\textquotesingle{}dicts\textquotesingle{}}\NormalTok{ : [\{}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{: [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]\}, \{}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{:[}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{8}\NormalTok{]\}, \{}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: [}\DecValTok{3}\NormalTok{,}\DecValTok{9}\NormalTok{]\}]\})}
\end{Highlighting}
\end{Shaded}

\hypertarget{working-with-a-dataframe}{%
\subsubsection{Working with a DataFrame}\label{working-with-a-dataframe}}

You can extract particular columns of a \texttt{DataFrame} by name

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{quote}
There is also a shortcut for accessing single columns, using Python's dot (\texttt{.}) notation.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.B}
\end{Highlighting}
\end{Shaded}

\begin{quote}
This notation can be more convenient if we need to perform operations on a single column. If we want to extract multiple columns, this notation will not work. Also, if we want to create new columns or replace existing columns, we need to use the array notation with the column name in quotes.
\end{quote}

Let's look at slicing a \texttt{DataFrame}

\hypertarget{extracting-rows-and-columns}{%
\subsubsection{Extracting rows and columns}\label{extracting-rows-and-columns}}

There are two extractor functions in \texttt{pandas}:

\begin{itemize}
\tightlist
\item
  \texttt{loc} extracts by label (index label, column label, slice of labels, etc.
\item
  \texttt{iloc} extracts by index (integers, slice objects, etc.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 }\OperatorTok{=}\NormalTok{ pd.DataFrame(rng.randint(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{, (}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{)), }
\NormalTok{                  index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{],}
\NormalTok{                  columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}two\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}three\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}four\textquotesingle{}}\NormalTok{])}
\NormalTok{df2}
\end{Highlighting}
\end{Shaded}

First, let's see what naively slicing this \texttt{DataFrame} does.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Ok, that works. It grabs one column from the dataset. How about the dot notation?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one}
\end{Highlighting}
\end{Shaded}

Let's see what this produces.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(df2.one)}
\end{Highlighting}
\end{Shaded}

So this is a series, so we can potentially do slicing of this series.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.one[:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Ok, so we have all the \texttt{Series} slicing available. The problem here is in semantics, in that we are grabbing one column and then slicing the rows. That doesn't quite work with our sense that a \texttt{DataFrame} is a rectangle with rows and columns, and we tend to think of rows, then columns.

Let's see if we can do column slicing with this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[:}\StringTok{\textquotesingle{}two\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

That's not what we want, of course. It's giving back the entire data frame. We'll come back to this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[[}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}three\textquotesingle{}}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

That works correctly though. We can give a list of column names. Ok.

How about row slices?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#df2[\textquotesingle{}a\textquotesingle{}] \# Doesn\textquotesingle{}t work}
\NormalTok{df2[}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{] }
\end{Highlighting}
\end{Shaded}

Ok, that works. It slices rows, but includes the largest index, like a \texttt{Series} but unlike \texttt{numpy} arrays.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\DecValTok{0}\NormalTok{:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Slices by location work too, but use the \texttt{numpy} slicing rules.

This entire extraction method becomes confusing. Let's simplify things for this, and then move on to more consistent ways to extract elements of a \texttt{DataFrame}. Let's agree on two things. If we're going the direct extraction route,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We will extract single columns of a \texttt{DataFrame} with \texttt{{[}{]}} or \texttt{.}, i.e., \texttt{df2{[}\textquotesingle{}one\textquotesingle{}{]}} or \texttt{df2.one}
\item
  We will extract slices of rows of a \texttt{DataFrame} using location only, i.e., \texttt{df2{[}:3{]}}.
\end{enumerate}

For everything else, we'll use two functions, \texttt{loc} and \texttt{iloc}.

\begin{itemize}
\tightlist
\item
  \texttt{loc} extracts elements like a matrix, using index and columns
\item
  \texttt{iloc} extracts elements like a matrix, using location
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.loc[:,}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}three\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.loc[}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.loc[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}three\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

So \texttt{loc} works just like a matrix, but with \texttt{pandas} slicing rules (include largest index)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iloc[:,}\DecValTok{1}\NormalTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iloc[}\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{,:]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.iloc[}\DecValTok{1}\NormalTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\texttt{iloc} slices like a matrix, but uses \texttt{numpy} slicing conventions (does \textbf{not} include highest index)

\hypertarget{boolean-selection}{%
\paragraph{Boolean selection}\label{boolean-selection}}

We can also use tests to extract data from a \texttt{DataFrame}. For example, we can extract only rows where column labeled \texttt{one} is greater than 3.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[df2.one }\OperatorTok{\textgreater{}} \DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

We can also do composite tests. Here we ask for rows where \texttt{one} is greater than 3 and \texttt{three} is less than 9

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[(df2.one }\OperatorTok{\textgreater{}} \DecValTok{3}\NormalTok{) }\OperatorTok{\&}\NormalTok{ (df2.three }\OperatorTok{\textless{}} \DecValTok{9}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\hypertarget{query}{%
\paragraph{\texorpdfstring{\texttt{query}}{query}}\label{query}}

\texttt{DataFrame}'s have a \texttt{query} method allowing selection using a Python expression

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OperatorTok{=} \DecValTok{10}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.rand(n, }\DecValTok{3}\NormalTok{), columns }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\StringTok{\textquotesingle{}abc\textquotesingle{}}\NormalTok{))}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[(df.a }\OperatorTok{\textless{}}\NormalTok{ df.b) }\OperatorTok{\&}\NormalTok{ (df.b }\OperatorTok{\textless{}}\NormalTok{ df.c)]}
\end{Highlighting}
\end{Shaded}

We can equivalently write this query as

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.query(}\StringTok{\textquotesingle{}(a \textless{} b) \& (b \textless{} c)\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{categorical-data}{%
\subsection{Categorical data}\label{categorical-data}}

\texttt{pandas} provides a \texttt{Categorical} function and a \texttt{category} object type to Python. This type is analogous to the \texttt{factor} data type in R. It is meant to address categorical or discrete variables, where we need to use them in analyses. Categorical variables typically take on a small number of unique values, like gender, blood type, country of origin, race, etc.

You can create categorical \texttt{Series} in a couple of ways:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OperatorTok{=}\NormalTok{ pd.Series([}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{], dtype}\OperatorTok{=}\StringTok{\textquotesingle{}category\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
    \StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{:}\FloatTok{3.}\NormalTok{,}
    \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{:rng.random\_sample(}\DecValTok{5}\NormalTok{),}
    \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: pd.Timestamp(}\StringTok{\textquotesingle{}20200512\textquotesingle{}}\NormalTok{),}
    \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{: np.array([}\DecValTok{6}\NormalTok{] }\OperatorTok{*} \DecValTok{5}\NormalTok{),}
    \StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{: pd.Categorical([}\StringTok{\textquotesingle{}yes\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}no\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}no\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}yes\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}no\textquotesingle{}}\NormalTok{]),}
    \StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}NIH\textquotesingle{}}\NormalTok{\})}
\NormalTok{df[}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{].astype(}\StringTok{\textquotesingle{}category\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can also create \texttt{DataFrame}'s where each column is categorical

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{: }\BuiltInTok{list}\NormalTok{(}\StringTok{\textquotesingle{}abcd\textquotesingle{}}\NormalTok{), }\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{: }\BuiltInTok{list}\NormalTok{(}\StringTok{\textquotesingle{}bdca\textquotesingle{}}\NormalTok{)\})}
\NormalTok{df\_cat }\OperatorTok{=}\NormalTok{ df.astype(}\StringTok{\textquotesingle{}category\textquotesingle{}}\NormalTok{)}
\NormalTok{df\_cat.dtypes}
\end{Highlighting}
\end{Shaded}

You can explore categorical data in a variety of ways

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_cat[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{].describe()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{].value\_counts()}
\end{Highlighting}
\end{Shaded}

One issue with categories is that, if a particular level of a category is not seen before, it can create an error. So you can pre-specify the categories you expect

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_cat[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.Categorical(}\BuiltInTok{list}\NormalTok{(}\StringTok{\textquotesingle{}aabb\textquotesingle{}}\NormalTok{), categories }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{])}
\NormalTok{df\_cat[}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{].value\_counts()}
\end{Highlighting}
\end{Shaded}

\hypertarget{missing-data}{%
\subsection{Missing data}\label{missing-data}}

Both \texttt{numpy} and \texttt{pandas} allow for missing values, which are a reality in data science. The missing values are coded as \texttt{np.nan}. Let's create some data and force some missing values

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.randn(}\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{), index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}g\textquotesingle{}}\NormalTok{], columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}two\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}three\textquotesingle{}}\NormalTok{]) }\CommentTok{\# pre{-}specify index and column names}
\NormalTok{df[}\StringTok{\textquotesingle{}four\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \DecValTok{20} \CommentTok{\# add a column named "four", which will all be 20}
\NormalTok{df[}\StringTok{\textquotesingle{}five\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{] }\OperatorTok{\textgreater{}} \DecValTok{0}
\NormalTok{df}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 }\OperatorTok{=}\NormalTok{ df.reindex([}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}f\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}g\textquotesingle{}}\NormalTok{])}
\NormalTok{df2.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{\textquotesingle{}background{-}color:yellow\textquotesingle{}}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

The code above is creating new blank rows based on the new index values, some of which are present in the existing data and some of which are missing.

We can create \emph{masks} of the data indicating where missing values reside in a data set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.isna()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2[}\StringTok{\textquotesingle{}one\textquotesingle{}}\NormalTok{].notna()}
\end{Highlighting}
\end{Shaded}

We can obtain complete data by dropping any row that has any missing value. This is called \emph{complete case analysis}, and you should be very careful using it. It is \emph{only} valid if we belive that the missingness is missing at random, and not related to some characteristic of the data or the data gathering process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.dropna(how}\OperatorTok{=}\StringTok{\textquotesingle{}any\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can also fill in, or \emph{impute}, missing values. This can be done using a single value..

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out1 }\OperatorTok{=}\NormalTok{ df2.fillna(value }\OperatorTok{=} \DecValTok{5}\NormalTok{)}

\NormalTok{out1.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{\textquotesingle{}background{-}color:yellow\textquotesingle{}}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

or a computed value like a column mean

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df3 }\OperatorTok{=}\NormalTok{ df2.copy()}
\NormalTok{df3 }\OperatorTok{=}\NormalTok{ df3.select\_dtypes(exclude}\OperatorTok{=}\NormalTok{[}\BuiltInTok{object}\NormalTok{])   }\CommentTok{\# remove non{-}numeric columns}
\NormalTok{out2 }\OperatorTok{=}\NormalTok{ df3.fillna(df3.mean())  }\CommentTok{\# df3.mean() computes column{-}wise means}

\NormalTok{out2.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{\textquotesingle{}background{-}color:yellow\textquotesingle{}}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

You can also impute based on the principle of \emph{last value carried forward} which is common in time series. This means that the missing value is imputed with the previous recorded value.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out3 }\OperatorTok{=}\NormalTok{ df2.fillna(method }\OperatorTok{=} \StringTok{\textquotesingle{}ffill\textquotesingle{}}\NormalTok{) }\CommentTok{\# Fill forward}

\NormalTok{out3.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{\textquotesingle{}background{-}color:yellow\textquotesingle{}}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out4 }\OperatorTok{=}\NormalTok{ df2.fillna(method }\OperatorTok{=} \StringTok{\textquotesingle{}bfill\textquotesingle{}}\NormalTok{) }\CommentTok{\# Fill backward}

\NormalTok{out4.style.applymap(}\KeywordTok{lambda}\NormalTok{ x: }\StringTok{\textquotesingle{}background{-}color:yellow\textquotesingle{}}\NormalTok{, subset }\OperatorTok{=}\NormalTok{ pd.IndexSlice[[}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{],:])}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-transformation}{%
\section{Data transformation}\label{data-transformation}}

\hypertarget{arithmetic-operations}{%
\subsection{Arithmetic operations}\label{arithmetic-operations}}

If you have a \texttt{Series} or \texttt{DataFrame} that is all numeric, you can add or multiply single numbers to all the elements together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.randn(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(A)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{+} \DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{*} \OperatorTok{{-}}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you have two compatible (same dimension) numeric \texttt{DataFrame}s, you can add, subtract, multiply and divide elementwise

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OperatorTok{=}\NormalTok{ pd.DataFrame(np.random.randn(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{) }\OperatorTok{+} \DecValTok{4}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{+}\NormalTok{ B)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{*}\NormalTok{ B)}
\end{Highlighting}
\end{Shaded}

If you have a \texttt{Series} with the same number of elements as the number of columns of a \texttt{DataFrame}, you can do arithmetic operations, with each element of the \texttt{Series} acting upon each column of the \texttt{DataFrame}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OperatorTok{=}\NormalTok{ pd.Series([}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{+}\NormalTok{ c)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(A }\OperatorTok{*}\NormalTok{ c)}
\end{Highlighting}
\end{Shaded}

This idea can be used to standardize a dataset, i.e.~make each column have mean 0 and standard deviation 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{means }\OperatorTok{=}\NormalTok{ A.mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{stds }\OperatorTok{=}\NormalTok{ A.std(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{)}

\NormalTok{(A }\OperatorTok{{-}}\NormalTok{ means)}\OperatorTok{/}\NormalTok{stds}
\end{Highlighting}
\end{Shaded}

\hypertarget{concatenation-of-data-sets}{%
\subsection{Concatenation of data sets}\label{concatenation-of-data-sets}}

Let's create some example data sets

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1 }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)],}
    \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)],}
    \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}c\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)],}
    \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}d\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{)]\})}

\NormalTok{df2 }\OperatorTok{=}\NormalTok{  pd.DataFrame(\{}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)],}
    \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)],}
    \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}c\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)],}
    \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}d\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{8}\NormalTok{)]\})}
\NormalTok{df3 }\OperatorTok{=}\NormalTok{  pd.DataFrame(\{}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)],}
    \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}b\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)],}
    \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}c\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)],}
    \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{: [}\StringTok{\textquotesingle{}d\textquotesingle{}}\OperatorTok{+}\BuiltInTok{str}\NormalTok{(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{12}\NormalTok{)]\})}
\end{Highlighting}
\end{Shaded}

We can concatenate these \texttt{DataFrame} objects by row

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{row\_concatenate }\OperatorTok{=}\NormalTok{ pd.concat([df1, df2, df3])}
\BuiltInTok{print}\NormalTok{(row\_concatenate)}
\end{Highlighting}
\end{Shaded}

This stacks the dataframes together. They are literally stacked, as is evidenced by the index values being repeated.

This same exercise can be done by the \texttt{append} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1.append(df2).append(df3)}
\end{Highlighting}
\end{Shaded}

Suppose we want to append a new row to \texttt{df1}. Lets create a new row.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_row }\OperatorTok{=}\NormalTok{ pd.Series([}\StringTok{\textquotesingle{}n1\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}n2\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}n3\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}n4\textquotesingle{}}\NormalTok{])}
\NormalTok{pd.concat([df1, new\_row])}
\end{Highlighting}
\end{Shaded}

That's a lot of missing values. The issue is that the we don't have column names in the \texttt{new\_row}, and the indices are the same, so pandas tries to append it my making a new column. The solution is to make it a \texttt{DataFrame}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_row }\OperatorTok{=}\NormalTok{ pd.DataFrame([[}\StringTok{\textquotesingle{}n1\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}n2\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}n3\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}n4\textquotesingle{}}\NormalTok{]], columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(new\_row)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.concat([df1, new\_row])}
\end{Highlighting}
\end{Shaded}

or

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1.append(new\_row)}
\end{Highlighting}
\end{Shaded}

\hypertarget{adding-columns}{%
\subsubsection{Adding columns}\label{adding-columns}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.concat([df1,df2,df3], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The option \texttt{axis=1} ensures that concatenation happens by columns. The default value \texttt{axis\ =\ 0} concatenates by rows.

Let's play a little game. Let's change the column names of \texttt{df2} and \texttt{df3} so they are not the same as \texttt{df1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2.columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{]}
\NormalTok{df3.columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{]}
\NormalTok{pd.concat([df1,df2,df3])}
\end{Highlighting}
\end{Shaded}

Now pandas ensures that all column names are represented in the new data frame, but with missing values where the row indices and column indices are mismatched. Some of this can be avoided by only joining on common columns. This is done using the \texttt{join} option ir \texttt{concat}. The default value is 'outer`, which is what you see. above

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.concat([df1, df3], join }\OperatorTok{=} \StringTok{\textquotesingle{}inner\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can do the same thing when joining by rows, using \texttt{axis\ =\ 0} and \texttt{join="inner"} to only join on rows with matching indices. Reminder that the indices are just labels and happen to be the row numbers by default.

\hypertarget{merging-data-sets}{%
\subsection{Merging data sets}\label{merging-data-sets}}

For this section we'll use a set of data from a survey, also used by Daniel Chen in ``Pandas for Everyone''

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{person }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/survey\_person.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{site }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/survey\_site.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{survey }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/survey\_survey.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{visited }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/survey\_visited.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(person)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(site)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(survey)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(visited)}
\end{Highlighting}
\end{Shaded}

There are basically four kinds of joins:

\begin{longtable}[]{@{}llll@{}}
\toprule
pandas & R & SQL & Description\tabularnewline
\midrule
\endhead
left & left\_join & left outer & keep all rows on left\tabularnewline
right & right\_join & right outer & keep all rows on right\tabularnewline
outer & outer\_join & full outer & keep all rows from both\tabularnewline
inner & inner\_join & inner & keep only rows with common keys\tabularnewline
\bottomrule
\end{longtable}

\includegraphics{graphs/joins.png}

The terms \texttt{left} and \texttt{right} refer to which data set you call first and second respectively.

We start with an left join

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2v\_merge }\OperatorTok{=}\NormalTok{ survey.merge(visited, left\_on }\OperatorTok{=} \StringTok{\textquotesingle{}taken\textquotesingle{}}\NormalTok{,right\_on }\OperatorTok{=} \StringTok{\textquotesingle{}ident\textquotesingle{}}\NormalTok{, how }\OperatorTok{=} \StringTok{\textquotesingle{}left\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(s2v\_merge)}
\end{Highlighting}
\end{Shaded}

Here, the left dataset is \texttt{survey} and the right one is \texttt{visited}. Since we're doing a left join, we keed all the rows from \texttt{survey} and add columns from \texttt{visited}, matching on the common key, called ``taken'' in one dataset and ``ident'' in the other. Note that the rows of \texttt{visited} are repeated as needed to line up with all the rows with common ``taken'' values.

We can now add location information, where the common key is the site code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s2v2loc\_merge }\OperatorTok{=}\NormalTok{ s2v\_merge.merge(site, how }\OperatorTok{=} \StringTok{\textquotesingle{}left\textquotesingle{}}\NormalTok{, left\_on }\OperatorTok{=} \StringTok{\textquotesingle{}site\textquotesingle{}}\NormalTok{, right\_on }\OperatorTok{=} \StringTok{\textquotesingle{}name\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(s2v2loc\_merge)}
\end{Highlighting}
\end{Shaded}

Lastly, we add the person information to this dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merged }\OperatorTok{=}\NormalTok{ s2v2loc\_merge.merge(person, how }\OperatorTok{=} \StringTok{\textquotesingle{}left\textquotesingle{}}\NormalTok{, left\_on }\OperatorTok{=} \StringTok{\textquotesingle{}person\textquotesingle{}}\NormalTok{, right\_on }\OperatorTok{=} \StringTok{\textquotesingle{}ident\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(merged.head())}
\end{Highlighting}
\end{Shaded}

You can merge based on multiple columns as long as they match up.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ps }\OperatorTok{=}\NormalTok{ person.merge(survey, left\_on }\OperatorTok{=} \StringTok{\textquotesingle{}ident\textquotesingle{}}\NormalTok{, right\_on }\OperatorTok{=} \StringTok{\textquotesingle{}person\textquotesingle{}}\NormalTok{)}
\NormalTok{vs }\OperatorTok{=}\NormalTok{ visited.merge(survey, left\_on }\OperatorTok{=} \StringTok{\textquotesingle{}ident\textquotesingle{}}\NormalTok{, right\_on }\OperatorTok{=} \StringTok{\textquotesingle{}taken\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(ps)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(vs)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ps\_vs }\OperatorTok{=}\NormalTok{ ps.merge(vs, }
\NormalTok{                left\_on }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}ident\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}taken\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}quant\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}reading\textquotesingle{}}\NormalTok{],}
\NormalTok{                right\_on }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}person\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}ident\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}quant\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}reading\textquotesingle{}}\NormalTok{]) }\CommentTok{\# The keys need to correspond}
\NormalTok{ps\_vs.head()}
\end{Highlighting}
\end{Shaded}

Note that since there are common column names, the merge appends \texttt{\_x} and \texttt{\_y} to denote which column came from the left and right, respectively.

\hypertarget{tidy-data-principles-and-reshaping-datasets}{%
\subsection{Tidy data principles and reshaping datasets}\label{tidy-data-principles-and-reshaping-datasets}}

The tidy data principle is a principle espoused by Dr.~Hadley Wickham, one of the foremost R developers. \href{http://vita.had.co.nz/papers/tidy-data.pdf}{Tidy data} is a structure for datasets to make them more easily analyzed on computers. The basic principles are

\begin{itemize}
\tightlist
\item
  Each row is an observation
\item
  Each column is a variable
\item
  Each type of observational unit forms a table
\end{itemize}

\begin{quote}
Tidy data is tidy in one way. Untidy data can be untidy in many ways
\end{quote}

Let's look at some examples.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ glob }\ImportTok{import}\NormalTok{ glob}
\NormalTok{filenames }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(glob(}\StringTok{\textquotesingle{}data/table*.csv\textquotesingle{}}\NormalTok{)) }\CommentTok{\# find files matching pattern. I know there are 6 of them}
\NormalTok{table1, table2, table3, table4a, table4b, table5 }\OperatorTok{=}\NormalTok{ [pd.read\_csv(f) }\ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ filenames] }\CommentTok{\# Use a list comprehension}
\end{Highlighting}
\end{Shaded}

This code imports data from 6 files matching a pattern. Python allows multiple assignments on the left of the \texttt{=}, and as each dataset is imported, it gets assigned in order to the variables on the left. In the second line I sort the file names so that they match the order in which I'm storing them in the 3rd line. The function \texttt{glob} does pattern-matching of file names.

The following tables refer to the number of TB cases and population in Afghanistan, Brazil and China in 1999 and 2000

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table1)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table2)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table3)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table4a) }\CommentTok{\# cases}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table4b) }\CommentTok{\# population}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(table5)}
\end{Highlighting}
\end{Shaded}

\textbf{Exercise:} Describe why and why not each of these datasets are tidy.

\hypertarget{melting-unpivoting-data}{%
\subsection{Melting (unpivoting) data}\label{melting-unpivoting-data}}

Melting is the operation of collapsing multiple columns into 2 columns, where one column is formed by the old column names, and the other by the corresponding values. Some columns may be kept fixed and their data are repeated to maintain the interrelationships between the variables.

We'll start with loading some data on income and religion in the US from the Pew Research Center.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pew }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/pew.csv\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(pew.head())}
\end{Highlighting}
\end{Shaded}

This dataset is considered in ``wide'' format. There are several issues with it, including the fact that column headers have data. Those column headers are income groups, that should be a column by tidy principles. Our job is to turn this dataset into ``long'' format with a column for income group.

We will use the function \texttt{melt} to achieve this. This takes a few parameters:

\begin{itemize}
\tightlist
\item
  \textbf{id\_vars} is a list of variables that will remain as is
\item
  \textbf{value\_vars} is a list of column nmaes that we will melt (or unpivot). By default, it will melt all columns not mentioned in id\_vars
\item
  \textbf{var\_name} is a string giving the name of the new column created by the headers (default: \texttt{variable})
\item
  \textbf{value\_name} is a string giving the name of the new column created by the values (default: \texttt{value})
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pew\_long }\OperatorTok{=}\NormalTok{ pew.melt(id\_vars }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}religion\textquotesingle{}}\NormalTok{], var\_name }\OperatorTok{=} \StringTok{\textquotesingle{}income\_group\textquotesingle{}}\NormalTok{, value\_name }\OperatorTok{=} \StringTok{\textquotesingle{}count\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(pew\_long.head())}
\end{Highlighting}
\end{Shaded}

\hypertarget{separating-columns-containing-multiple-variables}{%
\subsection{Separating columns containing multiple variables}\label{separating-columns-containing-multiple-variables}}

We will use an Ebola dataset to illustrate this principle

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/country\_timeseries.csv\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(ebola.head())}
\end{Highlighting}
\end{Shaded}

Note that for each country we have two columns -- one for cases (number infected) and one for deaths. Ideally we want one column for country, one for cases and one for deaths.

The first step will be to melt this data sets so that the column headers in question from a column and the corresponding data forms a second column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola\_long }\OperatorTok{=}\NormalTok{ ebola.melt(id\_vars }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Day\textquotesingle{}}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(ebola\_long.head())}
\end{Highlighting}
\end{Shaded}

We now need to split the data in the \texttt{variable} column to make two columns. One will contain the country name and the other either Cases or Deaths. We will use some string manipulation functions that we will see later to achieve this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable\_split }\OperatorTok{=}\NormalTok{ ebola\_long[}\StringTok{\textquotesingle{}variable\textquotesingle{}}\NormalTok{].}\BuiltInTok{str}\NormalTok{.split(}\StringTok{\textquotesingle{}\_\textquotesingle{}}\NormalTok{, expand}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\CommentTok{\# split on the \textasciigrave{}\_\textasciigrave{} character}
\BuiltInTok{print}\NormalTok{(variable\_split[:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

The \texttt{expand=True} option forces the creation of an \texttt{DataFrame} rather than a list

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(variable\_split)}
\end{Highlighting}
\end{Shaded}

We can now concatenate this to the original data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable\_split.columns }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}status\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{]}

\NormalTok{ebola\_parsed }\OperatorTok{=}\NormalTok{ pd.concat([ebola\_long, variable\_split], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}

\NormalTok{ebola\_parsed.drop(}\StringTok{\textquotesingle{}variable\textquotesingle{}}\NormalTok{, axis }\OperatorTok{=} \DecValTok{1}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\CommentTok{\# Remove the column named "variable" and replace the old data with the new one in the same location}

\BuiltInTok{print}\NormalTok{(ebola\_parsed.head())}
\end{Highlighting}
\end{Shaded}

\hypertarget{pivotspread-datasets}{%
\subsection{Pivot/spread datasets}\label{pivotspread-datasets}}

If we wanted to, we could also make two columns based on cases and deaths, so for each country and date you could easily read off the cases and deaths. This is achieved using the \texttt{pivot\_table} function.

In the \texttt{pivot\_table} syntax, \texttt{index} refers to the columns we don't want to change, \texttt{columns} refers to the column whose values will form the column names of the new columns, and \texttt{values} is the name of the column that will form the values in the pivoted dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola\_parsed.pivot\_table(index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Day\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{], columns }\OperatorTok{=} \StringTok{\textquotesingle{}status\textquotesingle{}}\NormalTok{, values }\OperatorTok{=} \StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This creates something called \texttt{MultiIndex} in the \texttt{pandas} \texttt{DataFrame}. This is useful in some advanced cases, but here, we just want a normal \texttt{DataFrame} back. We can achieve that by using the \texttt{reset\_index} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ebola\_parsed.pivot\_table(index }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}Day\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{], columns }\OperatorTok{=} \StringTok{\textquotesingle{}status\textquotesingle{}}\NormalTok{, values }\OperatorTok{=} \StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{).reset\_index()}
\end{Highlighting}
\end{Shaded}

Pivoting is a 2-column to many-column operation, with the number of columns formed depending on the number of unique values present in the column of the original data that is entered into the \texttt{columns} argument of \texttt{pivot\_table}

\textbf{Exercise:} Load the file \texttt{weather.csv} into Python and work on making it a tidy dataset. It requires melting and pivoting. The dataset comprises of the maximun and minimum temperatures recorded each day in 2010. There are lots of missing value. Ultimately we want columns for days of the month, maximum temperature and minimum tempearture along with the location ID, the year and the month.

\hypertarget{data-aggregation-and-split-apply-combine}{%
\section{Data aggregation and split-apply-combine}\label{data-aggregation-and-split-apply-combine}}

We'll use the Gapminder dataset for this section

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/gapminder.tsv\textquotesingle{}}\NormalTok{, sep }\OperatorTok{=} \StringTok{\textquotesingle{}}\CharTok{\textbackslash{}t}\StringTok{\textquotesingle{}}\NormalTok{) }\CommentTok{\# data is tab{-}separated, so we use \textasciigrave{}\textbackslash{}t\textasciigrave{} to specify that}
\end{Highlighting}
\end{Shaded}

The paradigm we will be exploring is often called \emph{split-apply-combine} or MapReduce or grouped aggregation. The basic idea is that you split a data set up by some feature, apply a recipe to each piece, compute the result, and then put the results back together into a dataset. This can be described in teh following schematic.

\includegraphics{graphs/split-apply-combine.png}

\texttt{pandas} is set up for this. It features the \texttt{groupby} function that allows the ``split'' part of the operation. We can then apply a function to each part and put it back together. Let's see how.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.head()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialStringTok{f"This dataset has }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(df[}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{].unique())}\SpecialCharTok{\}}\SpecialStringTok{ countries in it"}
\end{Highlighting}
\end{Shaded}

One of the variables in this dataset is life expectancy at birth, \texttt{lifeExp}. Suppose we want to find the average life expectancy of each country over the period of study.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{)[}\StringTok{\textquotesingle{}lifeExp\textquotesingle{}}\NormalTok{].mean()}
\end{Highlighting}
\end{Shaded}

So what's going on here? First, we use the \texttt{groupby} function, telling \texttt{pandas} to split the dataset up by values of the column \texttt{country}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\texttt{pandas} won't show you the actual data, but will tell you that it is a grouped dataframe object. This means that each element of this object is a \texttt{DataFrame} with data from one country.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{).ngroups}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{).get\_group(}\StringTok{\textquotesingle{}United Kingdom\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{).get\_group(}\StringTok{\textquotesingle{}United Kingdom\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg\_lifeexp\_country }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{).lifeExp.mean()}
\NormalTok{avg\_lifeexp\_country[}\StringTok{\textquotesingle{}United Kingdom\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{).get\_group(}\StringTok{\textquotesingle{}United Kingdom\textquotesingle{}}\NormalTok{).lifeExp.mean()}
\end{Highlighting}
\end{Shaded}

Let's look at if life expectancy has gone up over time, by continent

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby([}\StringTok{\textquotesingle{}continent\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{]).lifeExp.mean()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{avg\_lifeexp\_continent\_yr }\OperatorTok{=}\NormalTok{ df.groupby([}\StringTok{\textquotesingle{}continent\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{]).lifeExp.mean().reset\_index()}
\NormalTok{avg\_lifeexp\_continent\_yr}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(avg\_lifeexp\_continent\_yr)}
\end{Highlighting}
\end{Shaded}

The aggregation function, in this case \texttt{mean}, does both the ``apply'' and ``combine'' parts of the process.

We can do quick aggregations with \texttt{pandas}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}continent\textquotesingle{}}\NormalTok{).lifeExp.describe()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}continent\textquotesingle{}}\NormalTok{).nth(}\DecValTok{10}\NormalTok{) }\CommentTok{\# Tenth observation in each group}
\end{Highlighting}
\end{Shaded}

You can also use functions from other modules, or your own functions in this aggregation work.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}continent\textquotesingle{}}\NormalTok{).lifeExp.agg(np.mean)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my\_mean(values):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(values)}
    \BuiltInTok{sum} \OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ value }\KeywordTok{in}\NormalTok{ values:}
        \BuiltInTok{sum} \OperatorTok{+=}\NormalTok{ value}
    \ControlFlowTok{return}\NormalTok{(}\BuiltInTok{sum}\OperatorTok{/}\NormalTok{n)}

\NormalTok{df.groupby(}\StringTok{\textquotesingle{}continent\textquotesingle{}}\NormalTok{).lifeExp.agg(my\_mean)}
\end{Highlighting}
\end{Shaded}

You can do many functions at once

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{).lifeExp.agg([np.count\_nonzero, np.mean, np.std])}
\end{Highlighting}
\end{Shaded}

You can also aggregate on different columns at the same time by passing a \texttt{dict} to the \texttt{agg} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{).agg(\{}\StringTok{\textquotesingle{}lifeExp\textquotesingle{}}\NormalTok{: np.mean,}\StringTok{\textquotesingle{}pop\textquotesingle{}}\NormalTok{: np.median,}\StringTok{\textquotesingle{}gdpPercap\textquotesingle{}}\NormalTok{: np.median\}).reset\_index()}
\end{Highlighting}
\end{Shaded}

\hypertarget{transformation}{%
\subsubsection{Transformation}\label{transformation}}

You can do grouped transformations using this same method. We will compute the z-score for each year, i.e.~we will substract the average life expectancy and divide by the standard deviation

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ my\_zscore(values):}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ np.mean(values)}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ np.std(values)}
    \ControlFlowTok{return}\NormalTok{((values }\OperatorTok{{-}}\NormalTok{ m)}\OperatorTok{/}\NormalTok{s)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{).lifeExp.transform(my\_zscore)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[}\StringTok{\textquotesingle{}lifeExp\_z\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{).lifeExp.transform(my\_zscore)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{).lifeExp\_z.mean()}
\end{Highlighting}
\end{Shaded}

\hypertarget{filter}{%
\subsubsection{Filter}\label{filter}}

We can split the dataset by values of one variable, and filter out those splits that fail some criterion. The following code only keeps countries with a population of at least 10 million at some point during the study period

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.groupby(}\StringTok{\textquotesingle{}country\textquotesingle{}}\NormalTok{).}\BuiltInTok{filter}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ d: d[}\StringTok{\textquotesingle{}pop\textquotesingle{}}\NormalTok{].}\BuiltInTok{max}\NormalTok{() }\OperatorTok{\textgreater{}} \DecValTok{10000000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-visualization-using-python}{%
\chapter{Data visualization using Python}\label{data-visualization-using-python}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

Data visualization is a basic task in data exploration and understanding. Humans are mainly visual creatures, and data visualization provides an opportunity to enhance communication of the story within the data. Often we find that data and the data-generating process is complex, and a visual representation of the data and our innate ability at pattern recognition can help reveal the complexities in a cognitively accessible way.

\hypertarget{an-example-gallery}{%
\subsection{An example gallery}\label{an-example-gallery}}

Data visualization has a long and storied history, from Florence Nightangle onwards. Dr.~Nightangle was a pioneer in data visualization and developed the \emph{rose plot} to represent causes of death in hospitals during the Crimean War.

\includegraphics{graphs/rose.jpg}

John Snow, in 1854, famously visualized the cholera outbreak in London, which showed the geographic proximity of cholera prevalence with particular water wells.

\includegraphics{graphs/snow_map.png}

In one of the more famous visualizations, considered by many to be an optimal use of display ink and space, Minard visualized Napoleon's disastrous campaign to Russia

\includegraphics{graphs/map-full-size1.png}

In more recent times, an employee at Facebook visualized all connections between users across the world, which clearly showed geographical associations with particular countries and regions.

\includegraphics{graphs/facebook-high-res-friendship-world-map-paul-butler.png}

\hypertarget{why-visualize-data}{%
\subsection{Why visualize data?}\label{why-visualize-data}}

We often rely on numerical summaries to help understand and distinguish datasets. In 1973, Anscombe published an influential set of 4 datasets, each with two variables and with the means, variances and correlations being identical. When you graphed these data, the differences in the datasets were clearly visible. This set is popularly known as Anscombe's quartet.

\includegraphics{graphs/anscombe.png}

A more recent experiment in data construction by Matejka and Fitzmaurice (2017) started with a representation of a dinosaur and created 10 more bivariate datasets which all shared the same univariate means and variances and the same pairwise correlations.

\includegraphics{graphs/datasaurus.png}

These examples clarify the need for visualization to better understand relationships between variables.

Even when using statistical visualization techniques, one has to be careful. Not all visualizations can discriminate between statistical characteristics. This was also explored by Matejka and Fitzmaurice.

\begin{longtable}[]{@{}ccc@{}}
\toprule
Strip plot & Boxplot & Violin plot\tabularnewline
\midrule
\endhead
\includegraphics{graphs/box1.png} & \includegraphics{graphs/box2.png} & \includegraphics{graphs/box3.png}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{conceptual-ideas}{%
\subsection{Conceptual ideas}\label{conceptual-ideas}}

\hypertarget{begin-with-the-consumer-in-mind}{%
\subsubsection{Begin with the consumer in mind}\label{begin-with-the-consumer-in-mind}}

\begin{itemize}
\tightlist
\item
  You have a deep understanding of the data you're presenting
\item
  The person seeing the visualization \textbf{doesn't}
\item
  Develop simpler visualizations first that are easier to explain
\end{itemize}

\hypertarget{tell-a-story}{%
\subsubsection{Tell a story}\label{tell-a-story}}

\begin{itemize}
\tightlist
\item
  Make sure the graphic is clear
\item
  Make sure the main point you want to make ``pops''
\end{itemize}

\hypertarget{a-matter-of-perception}{%
\subsubsection{A matter of perception}\label{a-matter-of-perception}}

\begin{itemize}
\tightlist
\item
  Color (including awareness of color deficiencies)
\item
  Shape
\item
  Fonts
\end{itemize}

\hypertarget{some-principles}{%
\subsubsection{Some principles}\label{some-principles}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data-ink ratio
\item
  No mental gymnastics

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    The graphic should be self-evident
  \item
    Context should be clear
  \end{enumerate}
\item
  Is a graph the wrong choice?
\item
  Focus on the consumer
\end{enumerate}

\begin{quote}
See \href{http://araastat.com/BIOF439/lectures/01-DataViz.pdf}{my slides} for some more opinionated ideas
\end{quote}

\hypertarget{plotting-in-python}{%
\section{Plotting in Python}\label{plotting-in-python}}

Let's take a very quick tour before we get into the weeds. We'll use the mtcars dataset as an exemplar dataset that we can import using \texttt{pandas}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.set\_context(}\StringTok{\textquotesingle{}paper\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.set\_style(}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{, \{}\StringTok{\textquotesingle{}font.family\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}Futura\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}text.color\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}1\textquotesingle{}}\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.set\_context(}\StringTok{\textquotesingle{}paper\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.set\_style(}\StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{, \{}\StringTok{\textquotesingle{}font.family\textquotesingle{}}\NormalTok{:}\StringTok{\textquotesingle{}Futura Medium\textquotesingle{}}\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/mtcars.csv\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{static-plots}{%
\subsection{Static plots}\label{static-plots}}

We will demonstrate plotting in what I'll call the \texttt{matplotlib} ecosystem. \texttt{matplotlib} is the venerable and powerful visualization package that was originally designed to emulate the Matlab plotting paradigm. It has since evolved and as become a bit more user-friendly. It is still quite granular and can facilitate a lot of custom plots once you become familiar with it. However, as a starting point, I think it's a bit much. We'll see a bit of what it can offer later.

We will consider two other options which are built on top of \texttt{matplotlib}, but are much more accessible. These are \texttt{pandas} and \texttt{seaborn}. The two packages have some different approaches, but both wrap \texttt{matplotlib} in higher-level code and decent choices so we don't need to get into the \texttt{matplotlib} trenches quite so much. We'll still call \texttt{matplotlib} in our code, since both these packages need it for some fine tuning. Both packages are also very much aligned to the \texttt{DataFrame} construct in \texttt{pandas}, so makes plotting a much more seamless experience.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.plot.scatter(x }\OperatorTok{=} \StringTok{\textquotesingle{}hp\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\CommentTok{\# mtcars.plot(x = \textquotesingle{}hp\textquotesingle{}, y = \textquotesingle{}mpg\textquotesingle{}, kind = \textquotesingle{}scatter\textquotesingle{});}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-2-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ mtcars, x }\OperatorTok{=} \StringTok{\textquotesingle{}hp\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-3-1} \end{center}

There are of course some other choices based on your background and preferences. For static plots, there are a couple of emulators of the popular R package \texttt{ggplot2}. These are \texttt{plotnine} and \texttt{ggplot}. \texttt{plotnine} seems a bit more developed and uses the \texttt{ggplot2} semantics of aesthetics and layers, with almost identical code syntax.

\begin{quote}
You can install \texttt{plotnine} using \texttt{conda}:

\begin{verbatim}
conda install -c conda-forge plotnine
\end{verbatim}
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ plotnine }\ImportTok{import} \OperatorTok{*}

\NormalTok{(ggplot(mtcars) }\OperatorTok{+} 
\NormalTok{  aes(x }\OperatorTok{=} \StringTok{\textquotesingle{}hp\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{) }\OperatorTok{+}
\NormalTok{  geom\_point())}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-4-1} \end{center}

\hypertarget{dynamic-or-interactive-plots}{%
\subsection{Dynamic or interactive plots}\label{dynamic-or-interactive-plots}}

There are several Python packages that wrap around Javascript plotting libraries that are so popular in web-based graphics like D3 and Vega. Three that deserve mention are \texttt{plotly}, \texttt{bokeh}, and \texttt{altair}.

\begin{quote}
If you actually want to experience the interactivity of the plots, please use the ``Live notebooks'' link in Canvas to run these notebooks. Otherwise, you can download the notebooks from the GitHub site and run them on your own computer.
\end{quote}

\texttt{plotly} is a Python package developed by the company \href{https://www.plotly.com}{Plot.ly} to interface with their interactive Javascript library either locally or via their web service. Plot.ly also develops an R package to interface with their products as well. It provides an intuitive syntax and ease of use, and is probably the more popular package for interactive graphics from both R and Python.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ plotly.express }\ImportTok{as}\NormalTok{ px}

\NormalTok{fig }\OperatorTok{=}\NormalTok{ px.scatter(mtcars, x }\OperatorTok{=} \StringTok{\textquotesingle{}hp\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{)}
\NormalTok{fig.show()}
\end{Highlighting}
\end{Shaded}

\texttt{bokeh} is an interactive visualization package developed by Anaconda. It is quite powerful, but its code can be rather verbose and granular

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ bokeh.plotting }\ImportTok{import}\NormalTok{ figure, output\_file}
\ImportTok{from}\NormalTok{ bokeh.io }\ImportTok{import}\NormalTok{ output\_notebook, show}
\NormalTok{output\_notebook()}
\NormalTok{p }\OperatorTok{=}\NormalTok{ figure()}
\NormalTok{p.xaxis.axis\_label }\OperatorTok{=} \StringTok{\textquotesingle{}Horsepower\textquotesingle{}}
\NormalTok{p.yaxis.axis\_label }\OperatorTok{=} \StringTok{\textquotesingle{}Miles per gallon\textquotesingle{}}

\NormalTok{p.circle(mtcars[}\StringTok{\textquotesingle{}hp\textquotesingle{}}\NormalTok{], mtcars[}\StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{], size}\OperatorTok{=}\DecValTok{10}\NormalTok{)}\OperatorTok{;}

\NormalTok{show(p)}
\end{Highlighting}
\end{Shaded}

\texttt{altair} that leverages ideas from Javascript plotting libraries and a distinctive code syntax that may appeal to some

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ altair }\ImportTok{as}\NormalTok{ alt}

\NormalTok{alt.Chart(mtcars).mark\_point().encode(}
\NormalTok{    x}\OperatorTok{=}\StringTok{\textquotesingle{}hp\textquotesingle{}}\NormalTok{,}
\NormalTok{    y}\OperatorTok{=}\StringTok{\textquotesingle{}mpg\textquotesingle{}}
\NormalTok{).interactive()}
\end{Highlighting}
\end{Shaded}

We won't focus on these dynamic packages in this workshop in the interests of time, but you can avail of several online resources for these.

\begin{longtable}[]{@{}ll@{}}
\toprule
Package & Resources\tabularnewline
\midrule
\endhead
plotly & \href{https://plotly.com/python/}{Fundamentals}\tabularnewline
bokeh & \href{https://mybinder.org/v2/gh/bokeh/bokeh-notebooks/master?filepath=tutorial\%2F00\%20-\%20Introduction\%20and\%20Setup.ipynb}{Tutorial}\tabularnewline
altair & \href{https://altair-viz.github.io/getting_started/overview.html}{Overview}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{univariate-plots}{%
\section{Univariate plots}\label{univariate-plots}}

We will be introducing plotting and code from 3 modules: \texttt{matplotlib}, \texttt{seaborn} and \texttt{pandas}. As we go forth, you may ask the question, which one should I learn? Chris Moffitt has the following advice.

A pathway to learning (\href{https://pbpython.com/effective-matplotlib.html}{Chris Moffit})

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Learn the basic matplotlib terminology, specifically what is a \texttt{Figure} and an \texttt{Axes} .
\item
  Always use the object-oriented interface. Get in the habit of using it from the start of your analysis. (\emph{not really getting into this, but basically don't use the Matlab form I'll show at the end, if you don't have to})
\item
  Start your visualizations with basic pandas plotting.
\item
  Use seaborn for the more complex statistical visualizations.
\item
  Use matplotlib to customize the pandas or seaborn visualization.
\end{enumerate}

\hypertarget{pandas-1}{%
\subsection{pandas}\label{pandas-1}}

\hypertarget{histogram}{%
\subsubsection{Histogram}\label{histogram}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars.plot.hist(y }\OperatorTok{=} \StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\CommentTok{\# mtcars.plot(y = \textquotesingle{}mpg\textquotesingle{}, kind = \textquotesingle{}hist\textquotesingle{})}
\CommentTok{\#mtcars[\textquotesingle{}mpg\textquotesingle{}].plot(kind = \textquotesingle{}hist\textquotesingle{})}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-8-1} \end{center}

\hypertarget{bar-plot}{%
\subsubsection{Bar plot}\label{bar-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\StringTok{\textquotesingle{}cyl\textquotesingle{}}\NormalTok{].value\_counts().plot.bar()}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-9-1} \end{center}

\hypertarget{density-plot}{%
\subsubsection{Density plot}\label{density-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mtcars[}\StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{].plot( kind }\OperatorTok{=} \StringTok{\textquotesingle{}density\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-10-1} \end{center}

\hypertarget{seaborn}{%
\subsection{seaborn}\label{seaborn}}

\hypertarget{histogram-1}{%
\subsubsection{Histogram}\label{histogram-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ax }\OperatorTok{=}\NormalTok{ sns.distplot(mtcars[}\StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{], kde}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-11-1} \end{center}

\hypertarget{bar-plot-1}{%
\subsubsection{Bar plot}\label{bar-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.countplot(data }\OperatorTok{=}\NormalTok{ mtcars, x }\OperatorTok{=} \StringTok{\textquotesingle{}cyl\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-12-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/diamonds.csv.gz\textquotesingle{}}\NormalTok{)}
\NormalTok{ordered\_colors }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}I\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}J\textquotesingle{}}\NormalTok{]}
\NormalTok{sns.catplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{, kind }\OperatorTok{=} \StringTok{\textquotesingle{}count\textquotesingle{}}\NormalTok{, color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-13-1} \end{center}

\hypertarget{density-plot-1}{%
\subsubsection{Density plot}\label{density-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.distplot(mtcars[}\StringTok{\textquotesingle{}mpg\textquotesingle{}}\NormalTok{], hist}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-14-1} \end{center}

\hypertarget{bivariate-plots}{%
\section{Bivariate plots}\label{bivariate-plots}}

\hypertarget{pandas-2}{%
\subsection{pandas}\label{pandas-2}}

\hypertarget{scatter-plot}{%
\subsubsection{Scatter plot}\label{scatter-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/diamonds.csv.gz\textquotesingle{}}\NormalTok{)}
\NormalTok{diamonds.plot(x }\OperatorTok{=} \StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, kind }\OperatorTok{=} \StringTok{\textquotesingle{}scatter\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-15-1} \end{center}

\hypertarget{box-plot}{%
\subsubsection{Box plot}\label{box-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds.boxplot(column }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, by }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-16-1} \end{center}

\hypertarget{seaborn-1}{%
\subsection{seaborn}\label{seaborn-1}}

\hypertarget{scatter-plot-1}{%
\subsubsection{Scatter plot}\label{scatter-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.regplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, fit\_reg}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-17-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.scatterplot(data}\OperatorTok{=}\NormalTok{diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, linewidth}\OperatorTok{=}\DecValTok{0}\NormalTok{)}\OperatorTok{;} 
\CommentTok{\# We set the linewidth to 0, otherwise the lines around the circles}
\CommentTok{\# appear white and wash out the figure. Try with any positive }
\CommentTok{\# value of linewidth}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/unnamed-chunk-1-1} \end{center}

\hypertarget{box-plot-1}{%
\subsubsection{Box plot}\label{box-plot-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ordered\_color }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}I\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}J\textquotesingle{}}\NormalTok{]}
\NormalTok{sns.catplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, }
\NormalTok{            order }\OperatorTok{=}\NormalTok{ ordered\_color, color }\OperatorTok{=} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, kind }\OperatorTok{=} \StringTok{\textquotesingle{}box\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-18-1} \end{center}

\hypertarget{violin-plot}{%
\subsubsection{Violin plot}\label{violin-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.catplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, }
\NormalTok{                kind }\OperatorTok{=} \StringTok{\textquotesingle{}violin\textquotesingle{}}\NormalTok{, order }\OperatorTok{=}\NormalTok{ ordered\_color)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-19-1} \end{center}

\hypertarget{barplot-categorical-vs-continuous}{%
\subsubsection{Barplot (categorical vs continuous)}\label{barplot-categorical-vs-continuous}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ordered\_colors }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}I\textquotesingle{}}\NormalTok{]}
\NormalTok{sns.barplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, order }\OperatorTok{=}\NormalTok{ ordered\_colors)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-20-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.barplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}cut\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-21-1} \end{center}

\hypertarget{joint-plot}{%
\subsubsection{Joint plot}\label{joint-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.jointplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-22-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.jointplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, kind }\OperatorTok{=} \StringTok{\textquotesingle{}reg\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-23-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.jointplot(data }\OperatorTok{=}\NormalTok{ diamonds, x }\OperatorTok{=} \StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{, kind }\OperatorTok{=} \StringTok{\textquotesingle{}hex\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-24-1} \end{center}

\hypertarget{facets-and-multivariate-data}{%
\section{Facets and multivariate data}\label{facets-and-multivariate-data}}

The basic idea in this section is to see how we can visualize more than two variables at a time. We will see two strategies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Put multiple graphs on the same frame, with each graph referring to a level of a 3rd variable
\item
  Create a grid of separate graphs, with each graph referring to a level of a 3rd variable
\end{enumerate}

This strategy also can work any time we need to visualize the data corresponding to different levels of a variable, say by gender or race or country.

In this example we're going to start with 4 time series, labelled A, B, C, D.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ts }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/ts.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{ts.dt }\OperatorTok{=}\NormalTok{ pd.to\_datetime(ts.dt) }\CommentTok{\# convert this column to a datetime object}
\NormalTok{ts.head()}
\end{Highlighting}
\end{Shaded}

For one strategy we will employ, it is actually a bit easier to change this to a wide data form, using \texttt{pivot}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfp }\OperatorTok{=}\NormalTok{ ts.pivot(index }\OperatorTok{=} \StringTok{\textquotesingle{}dt\textquotesingle{}}\NormalTok{, columns }\OperatorTok{=} \StringTok{\textquotesingle{}kind\textquotesingle{}}\NormalTok{, values }\OperatorTok{=} \StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{)}
\NormalTok{dfp.head()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\NormalTok{dfp.plot(ax}\OperatorTok{=}\NormalTok{ax)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-27-1} \end{center}

This creates 4 separate time series plots, one for each of the columns labeled A, B, C and D. The x-axis is determined by \texttt{dfp.index}, which during the pivoting operation, we deemed was the values of \texttt{dt} in the original data.

Using \texttt{seaborn}\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.lineplot(data }\OperatorTok{=}\NormalTok{ dfp)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-28-1} \end{center}

However, we can achieve this same plot using the original data, and \texttt{seaborn}, in rather short order

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.lineplot(data }\OperatorTok{=}\NormalTok{ ts, x }\OperatorTok{=} \StringTok{\textquotesingle{}dt\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{, hue }\OperatorTok{=} \StringTok{\textquotesingle{}kind\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-29-1} \end{center}

In this plot, assigning a variable to \texttt{hue} tells seaborn to draw lines (in this case) of different hues based on values of that variable.

We can use a bit more granular and explicit code for this as well. This allows us a bit more control of the plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(ts, hue }\OperatorTok{=} \StringTok{\textquotesingle{}kind\textquotesingle{}}\NormalTok{, height }\OperatorTok{=} \DecValTok{5}\NormalTok{, aspect }\OperatorTok{=} \FloatTok{1.5}\NormalTok{)}
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(plt.plot, }\StringTok{\textquotesingle{}dt\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{).add\_legend()}
\NormalTok{g.ax.}\BuiltInTok{set}\NormalTok{(xlabel }\OperatorTok{=} \StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{,}
\NormalTok{        ylabel }\OperatorTok{=} \StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{,}
\NormalTok{        title }\OperatorTok{=} \StringTok{\textquotesingle{}Time series\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}

\CommentTok{\#\# All of this code chunk needs to be run at one time, otherwise you get weird errors. This}
\CommentTok{\#\# is true for many plotting commands which are composed of multiple commands. }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-30-1} \end{center}

The \texttt{FacetGrid} tells \texttt{seaborn} that we're going to layer graphs, with layers based on \texttt{hue} and the hues being determined by values of \texttt{kind}. Notice that we can add a few more details like the aspect ratio of the plot and so on. The documentation for \href{https://seaborn.pydata.org/generated/seaborn.FacetGrid.html}{FacetGrid}, which we will also use for facets below, may be helpful in finding all the options you can control.

We can also show more than one kind of layer on a single graph

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmri }\OperatorTok{=}\NormalTok{ sns.load\_dataset(}\StringTok{\textquotesingle{}fmri\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}seaborn{-}notebook\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{\textquotesingle{}timepoint\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}signal\textquotesingle{}}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-32-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{\textquotesingle{}timepoint\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}signal\textquotesingle{}}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri, kind }\OperatorTok{=} \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-33-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{\textquotesingle{}timepoint\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}signal\textquotesingle{}}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri, kind }\OperatorTok{=} \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{, hue }\OperatorTok{=}\StringTok{\textquotesingle{}event\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-34-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{\textquotesingle{}timepoint\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}signal\textquotesingle{}}\NormalTok{, data }\OperatorTok{=}\NormalTok{ fmri, hue }\OperatorTok{=} \StringTok{\textquotesingle{}region\textquotesingle{}}\NormalTok{, }
\NormalTok{            style }\OperatorTok{=} \StringTok{\textquotesingle{}event\textquotesingle{}}\NormalTok{, kind }\OperatorTok{=} \StringTok{\textquotesingle{}line\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-35-1} \end{center}

Here we use color to show the region, and line style (solid vs dashed) to show the event.

\hypertarget{scatter-plots-by-group}{%
\subsubsection{Scatter plots by group}\label{scatter-plots-by-group}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(diamonds, hue }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{, height }\OperatorTok{=} \FloatTok{7.5}\NormalTok{)}
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(plt.scatter, }\StringTok{\textquotesingle{}carat\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{).add\_legend()}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-36-1} \end{center}

Notice that this arranges the colors and values for the \texttt{color} variable in random order. If we have a preferred order we can impose that using the option \texttt{hue\_order}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clarity\_ranking }\OperatorTok{=}\NormalTok{ [}\StringTok{"I1"}\NormalTok{, }\StringTok{"SI2"}\NormalTok{, }\StringTok{"SI1"}\NormalTok{, }\StringTok{"VS2"}\NormalTok{, }\StringTok{"VS1"}\NormalTok{, }\StringTok{"VVS2"}\NormalTok{, }\StringTok{"VVS1"}\NormalTok{, }\StringTok{"IF"}\NormalTok{]}
\NormalTok{sns.scatterplot(x}\OperatorTok{=}\StringTok{"carat"}\NormalTok{, y}\OperatorTok{=}\StringTok{"price"}\NormalTok{,}
\NormalTok{                hue}\OperatorTok{=}\StringTok{"clarity"}\NormalTok{, size}\OperatorTok{=}\StringTok{"depth"}\NormalTok{,}
\NormalTok{                hue\_order}\OperatorTok{=}\NormalTok{clarity\_ranking,}
\NormalTok{                sizes}\OperatorTok{=}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{8}\NormalTok{), linewidth}\OperatorTok{=}\DecValTok{0}\NormalTok{,}
\NormalTok{                data}\OperatorTok{=}\NormalTok{diamonds)}\OperatorTok{;}
\NormalTok{plt.show() }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-37-1} \end{center}

\hypertarget{facets}{%
\subsection{Facets}\label{facets}}

Facets or trellis graphics is a visualization method where we draw multiple plots in a grid, with each plot corresponding to unique values of a particular variable or combinations of variables. This has also been called \emph{small multiples}.

We'll proceed with an example using the \texttt{iris} dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/iris.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{iris.head()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(iris, col }\OperatorTok{=} \StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{, hue }\OperatorTok{=} \StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{, height }\OperatorTok{=} \DecValTok{5}\NormalTok{)}
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(plt.scatter, }\StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{).add\_legend()}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-39-1} \end{center}

Here we use \texttt{FacetGrid} to indicate that we're creating multiple subplots by specifying the option \texttt{col} (for column). So this code says we are going to create one plot per level of species, arranged as separate columns (or in effect along one row). You could also specify \texttt{row} which would arrange the plots one to a row, or, in effect, in one column.

The \texttt{map} function says, take the facets I've defined and stored in \texttt{g}, and in each one, plot a scatter plot with \texttt{sepal\_width} on the x-axis and \texttt{sepal\_length} on the y-axis.

We could also use \texttt{relplot} for a more compact solution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{, data }\OperatorTok{=}\NormalTok{ iris, }
\NormalTok{            col }\OperatorTok{=} \StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{, hue }\OperatorTok{=} \StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-40-1} \end{center}

A bit more of a complicated example, using the \texttt{fmri} data, where we're coloring lines based on the subject, and creating a 2-d grid, where region of the brain in along columns and event type is along rows.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x}\OperatorTok{=}\StringTok{"timepoint"}\NormalTok{, y}\OperatorTok{=}\StringTok{"signal"}\NormalTok{, hue}\OperatorTok{=}\StringTok{"subject"}\NormalTok{,}
\NormalTok{            col}\OperatorTok{=}\StringTok{"region"}\NormalTok{, row}\OperatorTok{=}\StringTok{"event"}\NormalTok{, height}\OperatorTok{=}\DecValTok{3}\NormalTok{,}
\NormalTok{            kind}\OperatorTok{=}\StringTok{"line"}\NormalTok{, estimator}\OperatorTok{=}\VariableTok{None}\NormalTok{, data}\OperatorTok{=}\NormalTok{fmri)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-41-1} \end{center}

In the following example, we want to show how each subject fares for each of the two events, just within the frontal region. We let \texttt{seaborn} figure out the layout, only specifying that we'll be going along rows (``by column'') and also saying we'll wrap around to the beginning once we've got to 5 columns. Note we use the \texttt{query} function to filter the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.relplot(x}\OperatorTok{=}\StringTok{"timepoint"}\NormalTok{, y}\OperatorTok{=}\StringTok{"signal"}\NormalTok{, hue}\OperatorTok{=}\StringTok{"event"}\NormalTok{, style}\OperatorTok{=}\StringTok{"event"}\NormalTok{,}
\NormalTok{            col}\OperatorTok{=}\StringTok{"subject"}\NormalTok{, col\_wrap}\OperatorTok{=}\DecValTok{5}\NormalTok{,}
\NormalTok{            height}\OperatorTok{=}\DecValTok{3}\NormalTok{, aspect}\OperatorTok{=}\FloatTok{.75}\NormalTok{, linewidth}\OperatorTok{=}\FloatTok{2.5}\NormalTok{,}
\NormalTok{            kind}\OperatorTok{=}\StringTok{"line"}\NormalTok{, data}\OperatorTok{=}\NormalTok{fmri.query(}\StringTok{"region == \textquotesingle{}frontal\textquotesingle{}"}\NormalTok{))}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-42-1} \end{center}

In the following example we want to compare the distribution of price from the diamonds dataset by color, and so it makes sense to create density plots of the price distribution and stack them one below the next so we can visually compare them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ordered\_colors }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}I\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}J\textquotesingle{}}\NormalTok{]}
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.FacetGrid(data }\OperatorTok{=}\NormalTok{ diamonds, row }\OperatorTok{=} \StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{, height }\OperatorTok{=} \FloatTok{1.7}\NormalTok{, }
\NormalTok{                  aspect }\OperatorTok{=} \DecValTok{4}\NormalTok{, row\_order }\OperatorTok{=}\NormalTok{ ordered\_colors)}
\NormalTok{g.}\BuiltInTok{map}\NormalTok{(sns.kdeplot, }\StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-43-1} \end{center}

You need to use \texttt{FacetGrid} to create sets of univariate plots since there is no particular method that allows univariate plots over a grid like \texttt{relplot} for bivariate plots.

\hypertarget{pairs-plots}{%
\subsection{Pairs plots}\label{pairs-plots}}

The pairs plot is a quick way to compare every pair of variables in a dataset (or at least, every pair of continuous variables) in a grid. You can specify what kind of univariate plot will be displayed on the diagonal locations on the grid, and which bivariate plots will be displayed on the off-diagonal locations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.pairplot(data}\OperatorTok{=}\NormalTok{iris)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-44-1} \end{center}

You can achieve more customization using \texttt{PairGrid}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{=}\NormalTok{ sns.PairGrid(iris, diag\_sharey}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;}
\NormalTok{g.map\_upper(sns.scatterplot)}\OperatorTok{;}
\NormalTok{g.map\_lower(sns.kdeplot, colors}\OperatorTok{=}\StringTok{"C0"}\NormalTok{)}\OperatorTok{;}
\NormalTok{g.map\_diag(sns.kdeplot, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-45-1} \end{center}

\hypertarget{customizing-the-look}{%
\section{Customizing the look}\label{customizing-the-look}}

\hypertarget{themes}{%
\subsection{Themes}\label{themes}}

There are several \href{https://matplotlib.org/3.2.1/gallery/style_sheets/style_sheets_reference.html}{themes} available in the modern \texttt{matplotlib}, some of which borrow from \texttt{seaborn}. You can see the available themes and play around.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.available}
\end{Highlighting}
\end{Shaded}

See some examples below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}fivethirtyeight\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-47-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}bmh\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-48-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}classic\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-49-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}ggplot\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-50-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}Solarize\_Light2\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.scatterplot(data }\OperatorTok{=}\NormalTok{ iris, x }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_width\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}sepal\_length\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-51-1} \end{center}

\begin{quote}
One small syntax point. You may have noticed in your own work that you get a little annoying line in the output when you plot. You can prevent that from happening by putting a semi-colon (\texttt{;}) after the last plotting command
\end{quote}

\hypertarget{finer-control-with-matplotlib}{%
\section{Finer control with matplotlib}\label{finer-control-with-matplotlib}}

\begin{figure}
\centering
\includegraphics{graphs/matplotlib-anatomy.png}
\caption{\url{https://matplotlib.org/tutorials/introductory/usage.html\#sphx-glr-tutorials-introductory-usage-py}}
\end{figure}

As you can see from the figure, you can control each aspect of the plot displayed above using \texttt{matplotlib}. I won't go into the details, and will leave it to you to look at the \texttt{matplotlib} \href{https://matplotlib.org/contents.html}{documentation} and \href{https://matplotlib.org/gallery/index.html}{examples} if you need to customize at this level of granularity.

The following is an example using pure \texttt{matplotlib}. You can see how you can build up a plot. The crucial part here is that you need to run the code from each chunk together.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ matplotlib.ticker }\ImportTok{import}\NormalTok{ FuncFormatter}

\NormalTok{data }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}Barton LLC\textquotesingle{}}\NormalTok{: }\FloatTok{109438.50}\NormalTok{,}
        \StringTok{\textquotesingle{}Frami, Hills and Schmidt\textquotesingle{}}\NormalTok{: }\FloatTok{103569.59}\NormalTok{,}
        \StringTok{\textquotesingle{}Fritsch, Russel and Anderson\textquotesingle{}}\NormalTok{: }\FloatTok{112214.71}\NormalTok{,}
        \StringTok{\textquotesingle{}Jerde{-}Hilpert\textquotesingle{}}\NormalTok{: }\FloatTok{112591.43}\NormalTok{,}
        \StringTok{\textquotesingle{}Keeling LLC\textquotesingle{}}\NormalTok{: }\FloatTok{100934.30}\NormalTok{,}
        \StringTok{\textquotesingle{}Koepp Ltd\textquotesingle{}}\NormalTok{: }\FloatTok{103660.54}\NormalTok{,}
        \StringTok{\textquotesingle{}Kulas Inc\textquotesingle{}}\NormalTok{: }\FloatTok{137351.96}\NormalTok{,}
        \StringTok{\textquotesingle{}Trantow{-}Barrows\textquotesingle{}}\NormalTok{: }\FloatTok{123381.38}\NormalTok{,}
        \StringTok{\textquotesingle{}White{-}Trantow\textquotesingle{}}\NormalTok{: }\FloatTok{135841.99}\NormalTok{,}
        \StringTok{\textquotesingle{}Will LLC\textquotesingle{}}\NormalTok{: }\FloatTok{104437.60}\NormalTok{\}}
\NormalTok{group\_data }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(data.values())}
\NormalTok{group\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(data.keys())}
\NormalTok{group\_mean }\OperatorTok{=}\NormalTok{ np.mean(group\_data)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plt.style.use(}\StringTok{\textquotesingle{}default\textquotesingle{}}\NormalTok{)}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-53-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\NormalTok{ax.barh(group\_names, group\_data)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-54-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots()}
\NormalTok{ax.barh(group\_names, group\_data)}
\NormalTok{ax.}\BuiltInTok{set}\NormalTok{(xlim }\OperatorTok{=}\NormalTok{ [}\OperatorTok{{-}}\DecValTok{10000}\NormalTok{, }\DecValTok{140000}\NormalTok{], xlabel }\OperatorTok{=} \StringTok{\textquotesingle{}Total Revenue\textquotesingle{}}\NormalTok{, ylabel }\OperatorTok{=} \StringTok{\textquotesingle{}Company\textquotesingle{}}\NormalTok{, }
\NormalTok{       title }\OperatorTok{=} \StringTok{\textquotesingle{}Company Revenue\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-55-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{))}
\NormalTok{ax.barh(group\_names, group\_data)}
\NormalTok{labels }\OperatorTok{=}\NormalTok{ ax.get\_xticklabels()}
\NormalTok{plt.setp(labels, rotation}\OperatorTok{=}\DecValTok{45}\NormalTok{, horizontalalignment}\OperatorTok{=}\StringTok{\textquotesingle{}right\textquotesingle{}}\NormalTok{)}
\NormalTok{ax.}\BuiltInTok{set}\NormalTok{(xlim}\OperatorTok{=}\NormalTok{[}\OperatorTok{{-}}\DecValTok{10000}\NormalTok{, }\DecValTok{140000}\NormalTok{], xlabel}\OperatorTok{=}\StringTok{\textquotesingle{}Total Revenue\textquotesingle{}}\NormalTok{, ylabel}\OperatorTok{=}\StringTok{\textquotesingle{}Company\textquotesingle{}}\NormalTok{,}
\NormalTok{       title}\OperatorTok{=}\StringTok{\textquotesingle{}Company Revenue\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-56-1} \end{center}

After you have created your figure, you do need to save it to disk so that you can use it in your Word or Markdown or PowerPoint document. You can see the formats available.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fig.canvas.get\_supported\_filetypes()}
\end{Highlighting}
\end{Shaded}

The type will be determined by the ending of the file name. You can add some options depending on the type. I'm showing an example of saving the figure to a PNG file. Typically I'll save figures to a vector graphics format like PDF, and then convert into other formats, since that results in minimal resolution loss. You of course have the option to save to your favorite format.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fig.savefig(\textquotesingle{}sales.png\textquotesingle{}, dpi = 300, bbox\_inches = \textquotesingle{}tight\textquotesingle{}) }
\end{Highlighting}
\end{Shaded}

\hypertarget{matlab-like-plotting}{%
\subsection{Matlab-like plotting}\label{matlab-like-plotting}}

\texttt{matplotlib} was originally developed to emulate Matlab. Though this kind of syntax is no longer recommended, it is still available and may be of use to those coming to Python from Matlab or Octave.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\NormalTok{plt.plot([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{])}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}some numbers\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-59-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\CommentTok{\# evenly sampled time at 200ms intervals}
\NormalTok{t }\OperatorTok{=}\NormalTok{ np.arange(}\FloatTok{0.}\NormalTok{, }\FloatTok{5.}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}

\CommentTok{\# red dashes, blue squares and green triangles}
\NormalTok{plt.plot(t, t, }\StringTok{\textquotesingle{}r{-}{-}\textquotesingle{}}\NormalTok{, t, t}\OperatorTok{**}\DecValTok{2}\NormalTok{, }\StringTok{\textquotesingle{}bs\textquotesingle{}}\NormalTok{, t, t}\OperatorTok{**}\DecValTok{3}\NormalTok{, }\StringTok{\textquotesingle{}g\^{}\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-60-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ f(t):}
    \ControlFlowTok{return}\NormalTok{ np.exp(}\OperatorTok{{-}}\NormalTok{t) }\OperatorTok{*}\NormalTok{ np.cos(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi}\OperatorTok{*}\NormalTok{t)}

\NormalTok{t1 }\OperatorTok{=}\NormalTok{ np.arange(}\FloatTok{0.0}\NormalTok{, }\FloatTok{5.0}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\NormalTok{t2 }\OperatorTok{=}\NormalTok{ np.arange(}\FloatTok{0.0}\NormalTok{, }\FloatTok{5.0}\NormalTok{, }\FloatTok{0.02}\NormalTok{)}

\NormalTok{plt.figure()}\OperatorTok{;}
\NormalTok{plt.subplot(}\DecValTok{211}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.plot(t1, f(t1), }\StringTok{\textquotesingle{}bo\textquotesingle{}}\NormalTok{, t2, f(t2), }\StringTok{\textquotesingle{}k\textquotesingle{}}\NormalTok{)}\OperatorTok{;}

\NormalTok{plt.subplot(}\DecValTok{212}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.plot(t2, np.cos(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.pi}\OperatorTok{*}\NormalTok{t2), }\StringTok{\textquotesingle{}r{-}{-}\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/03-python-vis-61-1} \end{center}

\hypertarget{resources}{%
\section{Resources}\label{resources}}

A really nice online resource for learning data visualization in Python is the \href{https://python-graph-gallery.com/}{Python Graph Gallery}. This site has many examples of different kinds of plots using \texttt{pandas}, \texttt{seaborn} and \texttt{matplotlib}

\hypertarget{statistical-analysis}{%
\chapter{Statistical analysis}\label{statistical-analysis}}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

Statistical analysis usually encompasses 3 activities in a data science workflow. These are (a) descriptive analysis, (b) hypothesis testing and (c) statistical modeling. Descriptive analysis refers to a description of the data, which includes computing summary statistics and drawing plots. Hypothesis testing usually refers to statistically seeing if two (or more) groups are different from each other based on some metrics. Modeling refers to fitting a curve to the data to describe the relationship patterns of different variables in a data set.

In terms of Python packages that can address these three tasks:

\begin{longtable}[]{@{}ll@{}}
\toprule
Task & Packages\tabularnewline
\midrule
\endhead
Descriptive statistics & pandas, numpy, matplotlib, seaborn\tabularnewline
Hypothesis testing & scipy, statsmodels\tabularnewline
Modeling & statsmodels, lifelines, scikit-learn\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{descriptive-statistics}{%
\section{Descriptive statistics}\label{descriptive-statistics}}

Descriptive statistics that are often computed are the mean, median, standard deviation, inter-quartile range, pairwise correlations, and the like. Most of these functions are available in \texttt{numpy}, and hence are available in \texttt{pandas}. We have already seen how we can compute these statistics and have even computed grouped statistics. For example, we will compute these using the diamonds dataset

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ scipy }\ImportTok{as}\NormalTok{ sc}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/diamonds.csv.gz\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds.groupby(}\StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{)[}\StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{].agg([np.mean, np.median, np.std])}
\end{Highlighting}
\end{Shaded}

There were other examples we saw yesterday along these lines. Refer to both the \texttt{python\_tools\_ds} and \texttt{python\_pandas} documents

\hypertarget{simulation-and-inference}{%
\section{Simulation and inference}\label{simulation-and-inference}}

Hypothesis testing is one of the areas where statistics is often used. There are functions for a lot of the standard statistical tests in \texttt{scipy} and \texttt{statsmodels}. However, I'm going to take a little detour to see if we can get some understanding of hypothesis tests using the powerful simulation capabilities of Python. We'll visit the in-built functions available in \texttt{scipy} and \texttt{statsmodels} as well.

\hypertarget{simulation-and-hypothesis-testing}{%
\subsection{Simulation and hypothesis testing}\label{simulation-and-hypothesis-testing}}

\textbf{Question:} You have a coin and you flip it 100 times. You get 54 heads. How likely is it that you have a fair coin?

We can simulate this process, which is random, using Python. The process of heads and tails from coin tosses can be modeled as a \href{https://en.wikipedia.org/wiki/Binomial_distribution}{\textbf{binomial} distribution}. We can repeat this experiment many many times on our computer, making the assumption that we have a fair coin, and then seeing how likely what we observed is under that assumption.

\begin{quote}
Simulation under reasonable assumptions is a great way to understand our data and the underlying data generating processes. In the modern era, it has most famously been used by Nate Silver of ESPN to simulate national elections in the US. There are many examples in engineering where simulations are done to understand a technology and figure out its tolerances and weaknesses, like in aircraft testing. It is also commonly used in epidemic modeling to help understand how an epidemic would spread under different conditions.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{) }\CommentTok{\# Seed the random number generator}

\NormalTok{x }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{100}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{) }\CommentTok{\# Simulate 100,000 experiments of tossing a fair coin 100 times}

\NormalTok{sns.distplot(x, kde}\OperatorTok{=}\VariableTok{True}\NormalTok{, rug}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{plt.axvline(}\DecValTok{54}\NormalTok{, color }\OperatorTok{=} \StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{)}\OperatorTok{;} \CommentTok{\# What we observed}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Number of heads\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.Series(x).describe() }\CommentTok{\# We convert to pd.Series to take advantage of the \textasciigrave{}describe\textasciigrave{} function.}
\end{Highlighting}
\end{Shaded}

What we see from the histogram and the description of the data above is the patterns in data we would expect if we repeated this random experiment. We can already make some observations. First, we do see that the average number of heads we expect to get is 50, which validates that our experiment is using a fair coin. Second, we can reasonably get as few as 27 heads and as many as 72 heads even with a fair coin. In fact, we could look at what values we would expect to see 95\% of the time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.quantile(x, [}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

This says that 95\% of the time we'll see values between 40 and 60. (This is \textbf{not} a confidence interval. This is the actual results of a simulation study. A confidence interval would be computed based on a \textbf{single} experiment, assuming a binomial distribution. We'll come to that later).

So how likely would we be to see the 54 heads in 100 tosses assuming a fair coin? This can be computed as the proportion of experiments

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.mean(x }\OperatorTok{\textgreater{}} \DecValTok{54}\NormalTok{) }\CommentTok{\# convince yourself of this}
\end{Highlighting}
\end{Shaded}

This is what would be considered the \emph{p-value} for the test that the coin is fair.

\begin{quote}
The p-value of a statistical hypothesis test is the likelihood that we would see an outcome at least as extreme as we observed under the assumption that the null hypothesis (H0) that we chose is actually true.

In our case, that null hypothesis is that the coin we're tossing is fair. The p-value \textbf{only} gives evidence against the null hypothesis, but does \textbf{not} give evidence for the null hypothesis. In other words, if the p-value is small (smaller than some threshold we deem reasonable), then we can claim evidence against the null hypothesis, but if the p-value is large, we cannot say the null hypothesis is true.
\end{quote}

What happens if we increase the number of tosses, and we look at the proportion of heads. We observe 54\% heads.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{10000}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{10000}
\NormalTok{sns.distplot(x)}
\NormalTok{plt.axvline(}\FloatTok{0.54}\NormalTok{, color }\OperatorTok{=} \StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Proportion of heads\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.Series(x).describe()}
\end{Highlighting}
\end{Shaded}

Well, that changed the game significantly. If we up the number of coin tosses per experiment to 10,000, so 100-fold increase, then we do not see very much variation in the proportion of tosses that are heads.

\begin{quote}
This is expected behavior because of a statistical theorem called the \emph{Law of Large Numbers}, which essentially says that if you do larger and larger sized random experiments with the same experimental setup, your estimate of the true population parameter (in this case the true chance of getting a head, or 0.5 for a fair coin) will become more and more precise.
\end{quote}

Now we see that for a fair coin, we should reasonably see between 47.8\% and 52\% of tosses should be heads. This is quite an improvement from the 27\%-72\% range we saw with 100 tosses.

We can compute our p-value in the same way as before.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.mean(x }\OperatorTok{\textgreater{}} \FloatTok{0.54}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So we would never see 54\% of our tosses be heads if we tossed a fair coin 10,000 times. Now, with a larger experiment, we would \textbf{reject} our null hypothesis H0 that we have a fair coin.

So same observation, but more data, changes our \emph{inference} from not having sufficient evidence to say that the coin isn't fair to saying that it isn't fair quite definitively. This is directly due to the increased precision of our estimates and thus our ability to differentiate between much smaller differences in the truth.

Let's see a bit more about what's going on here. Suppose we assume that the coin's true likelihood of getting a head is really 0.55, so a very small bias towards heads.

\begin{quote}
Food for thought: Is the difference between 0.50 and 0.54 worth worrying about? It probably depends.
\end{quote}

We're going to compare what we would reasonably see over many repeated experiments given the coin has a 0.50 (fair) and a 0.55 (slightly biased) chance of a head. First, we'll do experiments of 100 tosses of a coin.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{)}
\NormalTok{x11 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{100}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{100} \CommentTok{\# Getting proportion of heads}
\NormalTok{x12 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{100}\NormalTok{, }\FloatTok{0.55}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{100} 

\NormalTok{sns.distplot(x11, label }\OperatorTok{=} \StringTok{\textquotesingle{}Fair\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.distplot(x12, label }\OperatorTok{=} \StringTok{\textquotesingle{}Biased\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Proportion of heads\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We see that there is a great deal of overlap in the potential outcomes over 100,000 repetitions of these experiments, so we have a lot of uncertainty about which model (fair or biased) is the truth.

Now, if we up our experiment to 10,000 tosses of each coin, and again repeat the experiment 100,000 times,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{205}\NormalTok{)}
\NormalTok{x21 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{10000}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{10000}
\NormalTok{x22 }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{10000}\NormalTok{, }\FloatTok{0.55}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\DecValTok{10000}

\NormalTok{sns.distplot(x21, label }\OperatorTok{=} \StringTok{\textquotesingle{}Fair\textquotesingle{}}\NormalTok{)}
\NormalTok{sns.distplot(x22, label }\OperatorTok{=} \StringTok{\textquotesingle{}Biased\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Proportion of heads\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.legend()}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We now find almost no overlap between the potential outcomes, so we can very easily distinguish the two models. This is part of what gathering more data (number of tosses) buys you.

We typically measure this ability to distinguish between two models using concepts of \emph{statistical power}, which is the likelihood that we would find an observation at least as extreme as what we observed, under the \textbf{alternative} model (in this case, the biased coin model). We can calculate the statistical power quite easily for the two sets of simulated experiments. Remember, we observed 54\% heads in our one instance of each experiment that we actually observed. By doing simulations, we're ``playing God'' and seeing what could have happened, but in practice we only do the experiment once (how many clinical trials of an expensive drug would you really want to do?).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pval1 }\OperatorTok{=}\NormalTok{ np.mean(x11 }\OperatorTok{\textgreater{}} \FloatTok{0.54}\NormalTok{)}
\NormalTok{pval2 }\OperatorTok{=}\NormalTok{ np.mean(x21 }\OperatorTok{\textgreater{}} \FloatTok{0.54}\NormalTok{)}

\NormalTok{power1 }\OperatorTok{=}\NormalTok{ np.mean(x12 }\OperatorTok{\textgreater{}} \FloatTok{0.54}\NormalTok{)}
\NormalTok{power2 }\OperatorTok{=}\NormalTok{ np.mean(x22 }\OperatorTok{\textgreater{}} \FloatTok{0.54}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}The p{-}value when n=100 is \textquotesingle{}}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(pval1, }\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}The p{-}value when n=10,000 is \textquotesingle{}}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(pval2, }\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Statistical power when n=100 is \textquotesingle{}}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(power1, }\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Statistical power when n=10,000 is \textquotesingle{}}\NormalTok{, np.}\BuiltInTok{round}\NormalTok{(power2, }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

So as \emph{n} goes up, the p-value for the same experimental outcome goes down and the statistical power goes up. This is a general rule with increasing sample size.

This idea can be used to design a two-armed experiment. Suppose we are looking at the difference in proportion of mice who gained weight between a wild-type mouse and a knockout variant. Since mice are expensive, let's limit the number of mice we'll use in each arm to 10. We expect 30\% of the wild-type mice to gain weight, and expect a higher proportion of the knockouts will gain weight. This is again the setup for a binomial experiment, with the number of ``coin tosses'' being 10 for each of the arms. We're going to do two sets of experiments, one for the WT and one for the KO, and see the difference in proportions of weight gain (`heads') between them, and repeat it 100,000 times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{304}\NormalTok{)}
\NormalTok{N }\OperatorTok{=} \DecValTok{10}
\NormalTok{weight\_gain\_wt0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{\# Get proportion}
\NormalTok{weight\_gain\_ko0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{\# Assume first (null hypothesis) that there is no difference}

\NormalTok{diff\_weight\_gain0 }\OperatorTok{=}\NormalTok{ weight\_gain\_ko0 }\OperatorTok{{-}}\NormalTok{ weight\_gain\_wt0}
\NormalTok{sns.distplot(diff\_weight\_gain0, kde}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;} \CommentTok{\# Since we only have 10 mice each, this histogram is not very smooth. }
                                           \CommentTok{\# No matter!}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/04-python-stat-14-1} \end{center}

We usually design the actual test by choosing a cutoff in the difference in proportions and stating that we will reject the null hypothesis if our observed difference exceeds this cutoff. We choose the cutoff so that the p-value of the cutoff is some pre-determined error rate, typically 0.05 or 5\% (This is not golden or set in stone. We'll discuss this later). Let's find that cutoff from this simulation. This will correspond to the 95th percentile of this simulated distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(np.quantile(diff\_weight\_gain0, }\FloatTok{0.95}\NormalTok{), }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This means that at least 5\% of the values will be 0.3 or bigger. In fact, this proportion is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.mean(diff\_weight\_gain0 }\OperatorTok{\textgreater{}} \FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

So we'll take 0.3 as the cutoff for our test (It's fine if the Type 1 error is more than 0.05. If we take the next largest value in the simulation, we dip below 0.05). We're basically done specifying the testing rule.

What we (and reviewers) like to know at this point is, what is the difference level for which you might get 80\% power. The thinking is that if the true difference was, say, \emph{p \textgreater{} 0} rather than 0 (under the null hypothesis), we would reject the null hypothesis, i.e., get our observed difference to be more than 0.3, at least 80\% of the time. We want to find out how big that value of \emph{p} is. In other words, what is the level of difference in proportions at which we can be reasonably certain that our test will REJECT H0, given our sample size, when the true difference in proportions is \emph{p}. Another way of saying this is how big does the difference in true proportions have to be before we would be fairly confident statistically of distinguishing that we have a difference between the two groups given our chosen sample size, i.e., fairly small overlaps in the two competing distributions.

We can also do this using simulation, by keeping the WT group at 0.3, increasing the KO group gradually, simulating the distribution of the difference in proportion and seeing at what point we get to a statistical power of about 80\%. Recall, we've already determined that our test will reject H0 when the observed difference is greater than 0.3

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{=}\NormalTok{ np.linspace(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{power }\OperatorTok{=}\NormalTok{ np.zeros(}\BuiltInTok{len}\NormalTok{(p1))}
\ControlFlowTok{for}\NormalTok{ i, p }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(p1):}
\NormalTok{    weight\_gain\_wt1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    weight\_gain\_ko1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, p, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    diff\_weight\_gain1 }\OperatorTok{=}\NormalTok{ weight\_gain\_ko1 }\OperatorTok{{-}}\NormalTok{ weight\_gain\_wt1}
\NormalTok{    power[i] }\OperatorTok{=}\NormalTok{ np.mean(diff\_weight\_gain1 }\OperatorTok{\textgreater{}} \FloatTok{0.3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.lineplot(p1, power)}
\NormalTok{plt.axhline(}\FloatTok{0.8}\NormalTok{, color }\OperatorTok{=} \StringTok{\textquotesingle{}black\textquotesingle{}}\NormalTok{, linestyle }\OperatorTok{=} \StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Statistical power\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Proportion in KO mice\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(p1[np.argmin(np.}\BuiltInTok{abs}\NormalTok{(power }\OperatorTok{{-}} \FloatTok{0.8}\NormalTok{))] }\OperatorTok{{-}} \FloatTok{0.3}\NormalTok{, }\DecValTok{2}\NormalTok{) }\CommentTok{\# Find the location in the p1 array where power is closest to 0.8}
\end{Highlighting}
\end{Shaded}

So to get to 80\% power, we would need the true difference in proportion to be 0.48, or that at least 78\% of KO mice should gain weight on average. This is quite a big difference, and its probably not very interesting scientifically to look for such a big difference, since it's quite unlikely.

If we could afford 100 mice per arm, what would this look like?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{304}\NormalTok{)}
\NormalTok{N }\OperatorTok{=} \DecValTok{100}
\NormalTok{weight\_gain\_wt0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{\# Get proportion}
\NormalTok{weight\_gain\_ko0 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N }\CommentTok{\# Assume first (null hypothesis) that there is no difference}

\NormalTok{diff\_weight\_gain0 }\OperatorTok{=}\NormalTok{ weight\_gain\_ko0 }\OperatorTok{{-}}\NormalTok{ weight\_gain\_wt0}
\NormalTok{cutoff }\OperatorTok{=}\NormalTok{ np.quantile(diff\_weight\_gain0, }\FloatTok{0.95}\NormalTok{)}

\NormalTok{p1 }\OperatorTok{=}\NormalTok{ np.linspace(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{power }\OperatorTok{=}\NormalTok{ np.zeros(}\BuiltInTok{len}\NormalTok{(p1))}
\ControlFlowTok{for}\NormalTok{ i, p }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(p1):}
\NormalTok{    weight\_gain\_wt1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, }\FloatTok{0.3}\NormalTok{, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    weight\_gain\_ko1 }\OperatorTok{=}\NormalTok{ rng.binomial(N, p, }\DecValTok{100000}\NormalTok{)}\OperatorTok{/}\NormalTok{N}
\NormalTok{    diff\_weight\_gain1 }\OperatorTok{=}\NormalTok{ weight\_gain\_ko1 }\OperatorTok{{-}}\NormalTok{ weight\_gain\_wt1}
\NormalTok{    power[i] }\OperatorTok{=}\NormalTok{ np.mean(diff\_weight\_gain1 }\OperatorTok{\textgreater{}}\NormalTok{ cutoff)}

\NormalTok{sns.lineplot(p1, power)}
\NormalTok{plt.axhline(}\FloatTok{0.8}\NormalTok{, color }\OperatorTok{=} \StringTok{\textquotesingle{}black\textquotesingle{}}\NormalTok{, linestyle }\OperatorTok{=} \StringTok{\textquotesingle{}{-}{-}\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\NormalTok{plt.ylabel(}\StringTok{\textquotesingle{}Statistical power\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{\textquotesingle{}Proportion in KO mice\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(p1[np.argmin(np.}\BuiltInTok{abs}\NormalTok{(power }\OperatorTok{{-}} \FloatTok{0.8}\NormalTok{))] }\OperatorTok{{-}} \FloatTok{0.3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The minimum detectable difference for 80\% power is now down to 0.17, so we'd need the KO mice in truth to show weight gain 47\% of the time, compared to 30\% in WT mice. This is more reasonable scientifically as a query.

\hypertarget{a-permutation-test}{%
\subsection{A permutation test}\label{a-permutation-test}}

A permutation test is a 2-group test that asks whether two groups are different with respect to some metric. Let us look at a breast cancer proteomics experiment to illustrate this. The experimental data contains protein expression for over 12 thousand proteins, along with clinical data. We can ask, for example, whether a particular protein expression differs by ER status.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brca }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/brca.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{brca.head()}
\end{Highlighting}
\end{Shaded}

We will first do the classical t-test, that is available in the \texttt{scipy} package.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ scipy }\ImportTok{as}\NormalTok{ sc}
\ImportTok{import}\NormalTok{ statsmodels }\ImportTok{as}\NormalTok{ sm}
\NormalTok{test\_probe }\OperatorTok{=} \StringTok{\textquotesingle{}NP\_001193600\textquotesingle{}}

\NormalTok{tst }\OperatorTok{=}\NormalTok{ sc.stats.ttest\_ind(brca[brca[}\StringTok{\textquotesingle{}ER Status\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}Positive\textquotesingle{}}\NormalTok{][test\_probe], }\CommentTok{\# Need [] since names have spaces}
\NormalTok{                   brca[brca[}\StringTok{\textquotesingle{}ER Status\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}Negative\textquotesingle{}}\NormalTok{][test\_probe], }
\NormalTok{                  nan\_policy }\OperatorTok{=} \StringTok{\textquotesingle{}omit\textquotesingle{}}\NormalTok{)}
\NormalTok{np.}\BuiltInTok{round}\NormalTok{(tst.pvalue, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The idea about a permutation test is that, if there is truly no difference then it shouldn't make a difference if we shuffled the labels of ER status over the study individuals. That's literally what we will do. We will do this several times, and look at the average difference in expression each time. This will form the null distribution under our assumption of no differences by ER status. We'll then see where our observed data falls, and then be able to compute a p-value.

The difference between the simulations we just did and a permutation test is that the permutation test is based only on the observed data. No particular models are assumed and no new data is simulated. All we're doing is shuffling the labels among the subjects, but keeping their actual data intact.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OperatorTok{=} \DecValTok{10000}

\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{294}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.where(brca[}\StringTok{\textquotesingle{}ER Status\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}Positive\textquotesingle{}}\NormalTok{, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ brca[test\_probe].to\_numpy()}

\NormalTok{obs\_diff }\OperatorTok{=}\NormalTok{ np.nanmean(y[x}\OperatorTok{==}\DecValTok{1}\NormalTok{]) }\OperatorTok{{-}}\NormalTok{ np.nanmean(y[x}\OperatorTok{=={-}}\DecValTok{1}\NormalTok{])}

\NormalTok{diffs }\OperatorTok{=}\NormalTok{ np.zeros(nsim)}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(nsim):}
\NormalTok{    x1 }\OperatorTok{=}\NormalTok{ rng.permutation(x)}
\NormalTok{    diffs[i] }\OperatorTok{=}\NormalTok{ np.nanmean(y[x1}\OperatorTok{==}\DecValTok{1}\NormalTok{]) }\OperatorTok{{-}}\NormalTok{ np.nanmean(y[x1 }\OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sns.distplot(diffs)}
\NormalTok{plt.axvline(x }\OperatorTok{=}\NormalTok{ obs\_diff, color }\OperatorTok{=}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pval }\OperatorTok{=}\NormalTok{ np.mean(np.}\BuiltInTok{abs}\NormalTok{(diffs) }\OperatorTok{\textgreater{}}\NormalTok{ np.}\BuiltInTok{abs}\NormalTok{(obs\_diff))}
\SpecialStringTok{f"P{-}value from permutation test is }\SpecialCharTok{\{}\NormalTok{pval}\SpecialCharTok{\}}\SpecialStringTok{"}
\end{Highlighting}
\end{Shaded}

This is pretty close to what we got from the t-test

\hypertarget{testing-many-proteins}{%
\subsection{Testing many proteins}\label{testing-many-proteins}}

We could do the permutation test all the proteins using the array operations in \texttt{numpy}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{expr\_names }\OperatorTok{=}\NormalTok{ [u }\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in} \BuiltInTok{list}\NormalTok{(brca.columns) }\ControlFlowTok{if}\NormalTok{ u.find(}\StringTok{\textquotesingle{}NP\textquotesingle{}}\NormalTok{) }\OperatorTok{\textgreater{}} \OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\CommentTok{\# Find all column names with NP}

\NormalTok{exprs }\OperatorTok{=}\NormalTok{ brca[expr\_names] }\CommentTok{\# Extract the protein data}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.where(brca[}\StringTok{\textquotesingle{}ER Status\textquotesingle{}}\NormalTok{]}\OperatorTok{==}\StringTok{\textquotesingle{}Positive\textquotesingle{}}\NormalTok{, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{obs\_diffs }\OperatorTok{=}\NormalTok{ exprs[x}\OperatorTok{==}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}\OperatorTok{{-}}\NormalTok{exprs[x}\OperatorTok{=={-}}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OperatorTok{=} \DecValTok{1000}
\NormalTok{diffs }\OperatorTok{=}\NormalTok{ np.zeros((nsim, exprs.shape[}\DecValTok{1}\NormalTok{]))}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(nsim):}
\NormalTok{    x1 }\OperatorTok{=}\NormalTok{ rng.permutation(x)}
\NormalTok{    diffs[i,:] }\OperatorTok{=}\NormalTok{exprs[x1}\OperatorTok{==}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{) }\OperatorTok{{-}}\NormalTok{ exprs[x1}\OperatorTok{=={-}}\DecValTok{1}\NormalTok{].mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pvals }\OperatorTok{=}\NormalTok{ np.zeros(exprs.shape[}\DecValTok{1}\NormalTok{])}
\BuiltInTok{len}\NormalTok{(pvals)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(pvals)):}
\NormalTok{    pvals[i] }\OperatorTok{=}\NormalTok{ np.mean(diffs[:,i] }\OperatorTok{\textgreater{}}\NormalTok{ obs\_diffs.iloc[i])}

\NormalTok{sns.distplot(pvals)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

This plot shows that there is probably some proteins which are differentially expressed between ER+ and ER- patients. (If no proteins had any difference, this histogram would be flat, since the p-values would be uniformly distributed). The ideas around Gene Set Enrichment Analysis (GSEA) can also be applied here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exprs\_shortlist }\OperatorTok{=}\NormalTok{ [u }\ControlFlowTok{for}\NormalTok{ i, u }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(}\BuiltInTok{list}\NormalTok{(exprs.columns)) }\ControlFlowTok{if}\NormalTok{ pvals[i] }\OperatorTok{\textless{}} \FloatTok{0.0001}\NormalTok{ ]}

\BuiltInTok{len}\NormalTok{(exprs\_shortlist)}
\end{Highlighting}
\end{Shaded}

This means that, if we considered a p-value cutoff for screening at 0.0001, we would select 486 of the 12395 proteins for further study.

\hypertarget{getting-a-confidence-interval-using-the-bootstrap}{%
\subsection{Getting a confidence interval using the bootstrap}\label{getting-a-confidence-interval-using-the-bootstrap}}

We can use simulations to obtain a model-free confidence interval for particular parameters of interest based on our observed data. The technique we will demonstrate is called the bootstrap. The idea is that if we sample with replacement from our observed data to get another data set of the same size as the observed data, and compute our statistic of interest, and then repeat this process many times, then the distribution of our statistic that we will obtain this way will be very similar to the true sampling distribution of the statistic if we could ``play God''. This has strong theoretical foundations from work done by several researchers in the 80s and 90s.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose the number of simulations \texttt{nsim}
\item
  for each iteration (1,\ldots,nsim)

  \begin{itemize}
  \tightlist
  \item
    Simulate a dataset with replacement from the original data.
  \item
    compute and store the statistic
  \end{itemize}
\item
  Compute the 2.5th and 97.5th percential of the distribution of the statistic. This is your confidence interval.
\end{enumerate}

Let's see this in action. Suppose we tossed a coin 100 times. We're going to find a confidence interval for the proportion of heads from this coin.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{304}\NormalTok{)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ rng.binomial(}\DecValTok{1}\NormalTok{, }\FloatTok{0.7}\NormalTok{, }\DecValTok{100}\NormalTok{)}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

This gives the sequence of heads (1) and tails (0), assuming the true probability of heads is 0.7.

We now create 100000 bootstrap samples from here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OperatorTok{=} \DecValTok{100000}

\NormalTok{boots }\OperatorTok{=}\NormalTok{ np.random.choice(x, (}\BuiltInTok{len}\NormalTok{(x), nsim), replace }\OperatorTok{=} \VariableTok{True}\NormalTok{) }\CommentTok{\# sample from the data}
\NormalTok{boot\_estimates }\OperatorTok{=}\NormalTok{ boots.mean(axis }\OperatorTok{=} \DecValTok{0}\NormalTok{) }\CommentTok{\# compute mean of each sample, i.e proportion of heads}

\NormalTok{sns.distplot(boot\_estimates)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{np.quantile(boot\_estimates, (}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{)) }\CommentTok{\# Find 2.5 and 97.5{-}th percentiles}
\end{Highlighting}
\end{Shaded}

So our 95\% bootstrap confidence interval is (0.66, 0.83). Our true value of 0.7 certainly falls in it.

\hypertarget{classical-hypothesis-testing}{%
\section{Classical hypothesis testing}\label{classical-hypothesis-testing}}

Python has the tools to do classic hypothesis testing as well. Several functions are available in the \texttt{scipy.stats} module. The commonly used tests that are available are as follows:

\begin{longtable}[]{@{}ll@{}}
\toprule
Function & Test\tabularnewline
\midrule
\endhead
\texttt{ttest\_1samp} & One-sample t-test\tabularnewline
\texttt{ttest\_ind} & Two-sample t-test\tabularnewline
\texttt{ttest\_rel} & Paired t-test\tabularnewline
\texttt{wilcoxon} & Wilcoxon signed-rank test (nonparametric paired t-test)\tabularnewline
\texttt{ranksum} & Wilcoxon rank-sum test (nonparametric 2-sample t-test)\tabularnewline
\texttt{chi2\_contingency} & Chi-square test for independence\tabularnewline
\texttt{fisher\_exact} & Fisher's exact test on a 2x2 contingency table\tabularnewline
\texttt{f\_oneway} & One-way ANOVA\tabularnewline
\texttt{pearsonr} & Testing for correlation\tabularnewline
&\tabularnewline
\bottomrule
\end{longtable}

There are also several tests in \texttt{statsmodels.stats}

\begin{longtable}[]{@{}ll@{}}
\toprule
Functions & Tests\tabularnewline
\midrule
\endhead
\texttt{proportions\_ztest} & Test for difference in proportions\tabularnewline
\texttt{mcnemar} & McNemar's test\tabularnewline
\texttt{sign\_test} & Sign test\tabularnewline
\texttt{multipletests} & p-value correction for multiple tests\tabularnewline
\texttt{fdrcorrection} & p-value correction by FDR\tabularnewline
&\tabularnewline
\bottomrule
\end{longtable}

We've seen an example of these tests earlier. .

\hypertarget{regression-analysis}{%
\section{Regression analysis}\label{regression-analysis}}

The regression modeling frameworks in Python are mainly in \texttt{statsmodels}, though some of it can be found in \texttt{scikit-learn} which we will see tomorrow. We will use the diamonds dataset for demonstration purposes. We will attempt to model the diamond price against several of the other diamond characteristics.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ statsmodels.api }\ImportTok{as}\NormalTok{ sm}
\ImportTok{import}\NormalTok{ statsmodels.formula.api }\ImportTok{as}\NormalTok{ smf }\CommentTok{\# Use the formula interface to statsmodels}

\NormalTok{mod1 }\OperatorTok{=}\NormalTok{ smf.glm(}\StringTok{\textquotesingle{}price \textasciitilde{} carat + clarity + depth + cut + color\textquotesingle{}}\NormalTok{, data }\OperatorTok{=}\NormalTok{ diamonds).fit()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1.summary()}
\end{Highlighting}
\end{Shaded}

This is the basic syntax for modeling in statsmodels. Let's go through and parse it.

One thing you notice is that we've written a formula inside the model

\begin{verbatim}
mod1 = smf.glm('price ~ carat + clarity + depth + cut + color', data = diamonds).fit()
\end{verbatim}

This is based on another Python package, \texttt{patsy}, which allows us to write the model like this. This will read as
``price depends on carat, clarity, depth, cut and color''. Underneath a lot is going on.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  color, clarity, and cut are all categorical variables. They actually need to be expanded into dummy variables, so we will have one column for each category level, which is 1 when the diamond is of that category and 0 otherwise.
\item
  An intercept terms is added
\item
  The dummy variables are concatenated to the continuous variables
\item
  The model is run
\end{enumerate}

We can see the dummy variables using \texttt{pandas}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.get\_dummies(diamonds)}
\end{Highlighting}
\end{Shaded}

\hypertarget{machine-learning-using-python}{%
\chapter{Machine Learning using Python}\label{machine-learning-using-python}}

\hypertarget{scikit-learn}{%
\section{Scikit-learn}\label{scikit-learn}}

Scikit-learn (\texttt{sklearn}) is the main Python package for machine learning. It is a widely-used and well-regarded package. However, there are a couple of challenges to using it given the usual \texttt{pandas}-based data munging pipeline.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{sklearn} requires that all inputs be numeric, and in fact, \texttt{numpy} arrays.
\item
  \texttt{sklearn} requires that all categorical variables by replaced by 0/1 dummy variables
\item
  \texttt{sklearn} requires us to separate the predictors from the outcome. We need to have one \texttt{X} matrix for the predictors and one \texttt{y} vector for the outcome.
\end{enumerate}

The big issue, of course, is the first point. Given we used \texttt{pandas} precisely because we wanted to be able to keep heterogenous data. We have to be able to convert non-numeric data to numeric. \texttt{pandas} does help us out with this problem. First of
all, we know that all \texttt{pandas} Series and DataFrame objects can be converted to \texttt{numpy} arrays using the \texttt{value} or \texttt{to\_numpy} functions. Second, we can easily extract a single variable from the data set using either the usual extracton methods or the
\texttt{pop} function. Third, \texttt{pandas} gives us a way to convert all categorical values to numeric dummy variables using the \texttt{get\_dummies} function. This is actually a more desirable solution than what you will see in cyberspace, which is to use the
\texttt{OneHotEncoder} function from \texttt{sklearn}. If the outcome variable is not numeric, we can \texttt{LabelEncoder} function from the \texttt{sklearn.preprocessing} submodule.

I just threw a bunch of jargon at you. Let's see what this means.

\hypertarget{transforming-the-outcometarget}{%
\subsection{Transforming the outcome/target}\label{transforming-the-outcometarget}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ sklearn}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}

\NormalTok{iris }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/iris.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{iris.head()}
\end{Highlighting}
\end{Shaded}

Let's hit the first issue first. We need to separate out the outcome (the variable we want to predict) from the predictors (in this case the sepal and petal measurements).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ iris[}\StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{]}
\NormalTok{X }\OperatorTok{=}\NormalTok{ iris.drop(}\StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{, axis }\OperatorTok{=} \DecValTok{1}\NormalTok{) }\CommentTok{\# drops column, makes a copy}
\end{Highlighting}
\end{Shaded}

Another way to do this is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ iris.pop(}\StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you look at this, \texttt{iris} now only has 4 columns. So we could just use \texttt{iris} after the \texttt{pop} application, as the predictor set

We still have to update \texttt{y} to become numeric. This is where the \texttt{sklearn} functions start to be handy

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ LabelEncoder}
\NormalTok{le }\OperatorTok{=}\NormalTok{ LabelEncoder()}
\NormalTok{y }\OperatorTok{=}\NormalTok{ le.fit\_transform(y)}
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

Let's talk about this code, since it's very typical of the way the \texttt{sklearn}
code works. First, we import a method (\texttt{LabelEncoder}) from the appropriate
\texttt{sklearn} module. The second line, \texttt{le\ =\ LabelEncoder()} works to ``turn on'' the
method. This is like taking a power tool off the shelf and plugging it in to a
socket. It's now ready to work. The third line does the actual work. The
\texttt{fit\_transform} function transforms the data you input into it based on the
method it is then attached to.

\begin{quote}
Let's make a quick analogy. You can plug in both a power washer and a
jackhammer to get them ready to go. You can then apply each of them to your
driveway. They ``transform'' the driveway in different ways depending on which
tool is used. The washer would ``transform'' the driveway by cleaning it, while
the jackhammer would transform the driveway by breaking it.
\end{quote}

There's an interesting invisible quirk to the code, though. The object \texttt{le} also got transformed during this
process. There were pieces added to it during the \texttt{fit\_transform} process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le }\OperatorTok{=}\NormalTok{ LabelEncoder()}
\NormalTok{d1 }\OperatorTok{=} \BuiltInTok{dir}\NormalTok{(le)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ le.fit\_transform( pd.read\_csv(}\StringTok{\textquotesingle{}data/iris.csv\textquotesingle{}}\NormalTok{)[}\StringTok{\textquotesingle{}species\textquotesingle{}}\NormalTok{])}
\NormalTok{d2 }\OperatorTok{=} \BuiltInTok{dir}\NormalTok{(le)}
\BuiltInTok{set}\NormalTok{(d2).difference(}\BuiltInTok{set}\NormalTok{(d1)) }\CommentTok{\# set of things in d2 but not in d1}
\end{Highlighting}
\end{Shaded}

So we see that there is a new component added, called \texttt{classes\_}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le.classes\_}
\end{Highlighting}
\end{Shaded}

So the original labels aren't destroyed; they are being stored. This can be useful.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{le.inverse\_transform([}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

So we can transform back from the numeric to the labels. Keep this in hand, since it will prove useful after
we have done some predictions using a ML model, which will give numeric predictions.

\hypertarget{transforming-the-predictors}{%
\subsection{Transforming the predictors}\label{transforming-the-predictors}}

Let's look at a second example. The \texttt{diamonds} dataset has several categorical variables that would need to be transformed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/diamonds.csv.gz\textquotesingle{}}\NormalTok{)}

\NormalTok{y }\OperatorTok{=}\NormalTok{ diamonds.pop(}\StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{).values}
\NormalTok{X }\OperatorTok{=}\NormalTok{ pd.get\_dummies(diamonds)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X.info()}
\end{Highlighting}
\end{Shaded}

So everything is now numeric!!. Let's take a peek inside.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X.columns}
\end{Highlighting}
\end{Shaded}

So, it looks like the continuous variables remain intact, but the categorical variables got exploded out. Each
variable name has a level with it, which represents the particular level it is representing. Each of these
variables, called dummy variables, are numerical 0/1 variables. For example, \texttt{color\_F} is 1 for those diamonds which have color F, and 0 otherwise.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd.crosstab(X[}\StringTok{\textquotesingle{}color\_F\textquotesingle{}}\NormalTok{], diamonds[}\StringTok{\textquotesingle{}color\textquotesingle{}}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-methods}{%
\section{The methods}\label{the-methods}}

We mentioned a bunch of methods in the slides. Let's look at where they are in \texttt{sklearn}

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.26\columnwidth}\raggedright
ML method\strut
\end{minipage} & \begin{minipage}[b]{0.68\columnwidth}\raggedright
Code to call it\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Decision Tree\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.tree.DecisionTreeClassifier}, \texttt{sklearn.tree.DecisionTreeRegressor}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Random Forest\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.ensemble.RandomForestClassifier}, \texttt{sklearn.ensemble.RandomForestRegressor}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Linear Regression\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.linear\_model.LinearRegression}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Logistic Regression\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.linear\_model.LogisticRegression}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
Support Vector Machines\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\texttt{sklearn.svm.LinearSVC}, \texttt{sklearn.svm.LinearSVR}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.26\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.68\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

The general method that the code will follow is :

\begin{verbatim}
from sklearn.... import Machine
machine = Machine(*parameters*)
machine.fit(X, y)
\end{verbatim}

\hypertarget{a-quick-example}{%
\subsection{A quick example}\label{a-quick-example}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeRegressor}

\NormalTok{lm }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{dt }\OperatorTok{=}\NormalTok{ DecisionTreeRegressor()}
\end{Highlighting}
\end{Shaded}

Lets manufacture some data

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{200}\NormalTok{)}
\NormalTok{y }\OperatorTok{=} \DecValTok{2} \OperatorTok{+} \DecValTok{3}\OperatorTok{*}\NormalTok{x }\OperatorTok{{-}} \DecValTok{5}\OperatorTok{*}\NormalTok{(x}\OperatorTok{**}\DecValTok{2}\NormalTok{)}
\NormalTok{d }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{: x\})}

\NormalTok{lm.fit(d,y)}
\NormalTok{dt.fit(d, y)}

\NormalTok{p1 }\OperatorTok{=}\NormalTok{ lm.predict(d)}
\NormalTok{p2 }\OperatorTok{=}\NormalTok{ dt.predict(d)}

\NormalTok{d[}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ y}
\NormalTok{d[}\StringTok{\textquotesingle{}lm\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ p1}
\NormalTok{d[}\StringTok{\textquotesingle{}dt\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ p2}

\NormalTok{D }\OperatorTok{=}\NormalTok{ pd.melt(d, id\_vars }\OperatorTok{=} \StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{)}

\NormalTok{sns.relplot(data}\OperatorTok{=}\NormalTok{D, x }\OperatorTok{=} \StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{, y }\OperatorTok{=} \StringTok{\textquotesingle{}value\textquotesingle{}}\NormalTok{, hue }\OperatorTok{=} \StringTok{\textquotesingle{}variable\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{BIOF085_Manual_files/figure-latex/05-python-learning-15-1} \end{center}

\hypertarget{a-data-analytic-example}{%
\section{A data analytic example}\label{a-data-analytic-example}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diamonds }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}data/diamonds.csv.gz\textquotesingle{}}\NormalTok{)}
\NormalTok{diamonds.info()}
\end{Highlighting}
\end{Shaded}

First, lets separate out the outcome (price) and the predictors

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OperatorTok{=}\NormalTok{ diamonds.pop(}\StringTok{\textquotesingle{}price\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

For many machine learning problems, it is useful to scale the numeric predictors so that they have mean 0 and
variance 1. First we need to separate out the categorical and numeric variables

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d1 }\OperatorTok{=}\NormalTok{ diamonds.select\_dtypes(include }\OperatorTok{=} \StringTok{\textquotesingle{}number\textquotesingle{}}\NormalTok{)}
\NormalTok{d2 }\OperatorTok{=}\NormalTok{ diamonds.select\_dtypes(exclude }\OperatorTok{=} \StringTok{\textquotesingle{}number\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now let's scale the columns of \texttt{d1}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ scale}

\NormalTok{bl }\OperatorTok{=}\NormalTok{ scale(d1)}
\NormalTok{bl}
\end{Highlighting}
\end{Shaded}

Woops!! We get a \texttt{numpy} array, not a \texttt{DataFrame}!!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bl }\OperatorTok{=}\NormalTok{ pd.DataFrame(scale(d1))}
\NormalTok{bl.columns }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(d1.columns)}
\NormalTok{d1 }\OperatorTok{=}\NormalTok{ bl}
\end{Highlighting}
\end{Shaded}

Now, let's recode the categorical variables into dummy variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d2 }\OperatorTok{=}\NormalTok{ pd.get\_dummies(d2)}
\end{Highlighting}
\end{Shaded}

and put them back together

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{=}\NormalTok{ pd.concat([d1,d2], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next we need to split the data into a training set and a test set. Usually we do this as an 80/20 split.
The purpose of the test set is to see how well the model works on an ``external'' data set. We don't touch the
test set until we're done with all our model building in the training set. We usually do the split using
random numbers. We'll put 40,000 observations in the training set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(X.index)}
\NormalTok{np.random.shuffle(ind)}

\NormalTok{X\_train, y\_train }\OperatorTok{=}\NormalTok{ X.loc[ind[:}\DecValTok{40000}\NormalTok{],:], y[ind[:}\DecValTok{40000}\NormalTok{]]}
\NormalTok{X\_test, y\_test }\OperatorTok{=}\NormalTok{ X.loc[ind[}\DecValTok{40000}\NormalTok{:],:], y[ind[}\DecValTok{40000}\NormalTok{:]]}
\end{Highlighting}
\end{Shaded}

There is another way to do this

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ train\_test\_split}

\NormalTok{X\_train, X\_test, y\_train, y\_test }\OperatorTok{=}\NormalTok{ train\_test\_split(X, y , test\_size }\OperatorTok{=} \FloatTok{0.2}\NormalTok{, random\_state}\OperatorTok{=} \DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now we will fit our models to the training data. Let's use a decision tree model, a random forest model, and a linear regression.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.tree }\ImportTok{import}\NormalTok{ DecisionTreeRegressor}
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestRegressor}

\NormalTok{lm }\OperatorTok{=}\NormalTok{ LinearRegression()}
\NormalTok{dt }\OperatorTok{=}\NormalTok{ DecisionTreeRegressor()}
\NormalTok{rf }\OperatorTok{=}\NormalTok{ RandomForestRegressor()}
\end{Highlighting}
\end{Shaded}

Now we will use our training data to fit the models

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit(X\_train, y\_train)}
\NormalTok{dt.fit(X\_train, y\_train)}
\NormalTok{rf.fit(X\_train, y\_train)}
\end{Highlighting}
\end{Shaded}

We now need to see how well the model fit the data. We'll use the R2 statistic to be our metric of choice to evaluate the model fit.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.metrics }\ImportTok{import}\NormalTok{  r2\_score}

\SpecialStringTok{f"""}
\SpecialStringTok{Linear regression: }\SpecialCharTok{\{}\NormalTok{r2\_score(y\_train, lm.predict(X\_train))}\SpecialCharTok{\}}\SpecialStringTok{, }
\SpecialStringTok{Decision tree: }\SpecialCharTok{\{}\NormalTok{r2\_score(y\_train, dt.predict(X\_train))}\SpecialCharTok{\}}\SpecialStringTok{,}
\SpecialStringTok{Random Forest: }\SpecialCharTok{\{}\NormalTok{r2\_score(y\_train, rf.predict(X\_train))}\SpecialCharTok{\}}
\SpecialStringTok{"""}
\end{Highlighting}
\end{Shaded}

This is pretty amazing. However, we know that if we try and predict using the same data we used to train
the model, we get better than expected results. One way to get a better idea about the true performance of the
model when we will try it on external data is to do cross-validation.

In cross-validation, we split the dataset up into 5 equal parts randomly. We then train the
model using 4 parts and predict the data on the 5th part. We do for all possible groups of 4 parts. We then
consider the overall performance of prediction.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ cross\_val\_score}
\NormalTok{cv\_score }\OperatorTok{=}\NormalTok{ cross\_val\_score(dt, X\_train, y\_train, cv}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\SpecialStringTok{f"CV error = }\SpecialCharTok{\{np.}\NormalTok{mean(cv\_score)}\SpecialCharTok{\}}\SpecialStringTok{"}
\end{Highlighting}
\end{Shaded}

If we weren't satisfied with this performance, we could optimize the parameters of the decision tree to see
if we could improve performance. The way to do that would be to use \texttt{sklearn.model\_selection.GridSearchCV}, giving
it ranges of the parameters we want to optimize. For a decision tree these would be the maximum depth of the tree, the size of the smallest leaf, and the maximum number of features (predictors) to consider at each split. See \texttt{help(DecisionTreeRegressor)} for more details.

So how does this do on the test set?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OperatorTok{=}\NormalTok{ dt.predict(X\_test)}
\NormalTok{r2\_score(y\_test, p)}
\end{Highlighting}
\end{Shaded}

\hypertarget{string-manipulation}{%
\chapter{String manipulation}\label{string-manipulation}}

String manipulation is one of Python's strong suites. It comes built in with methods for strings, and the \texttt{re} module (for \emph{regular expressions}) ups that power many fold.

Strings are objects that we typically see in quotes. We can also check if a variable is a string.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=} \StringTok{\textquotesingle{}Les Miserable\textquotesingle{}}

\BuiltInTok{type}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

Strings are a little funny. They look like they are one thing, but they can act like lists. In some sense they
are really a container of characters. So we can have

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(a)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[:}\DecValTok{4}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[}\DecValTok{3}\NormalTok{:}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

The rules are basically the same as lists. To make this explicit, let's consider the word `bare'.
In terms of positions, we can write this out.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\endhead
index & 0 & 1 & 2 & 3\tabularnewline
string & b & a & r & e\tabularnewline
neg index & -4 & -3 & -2 & -1\tabularnewline
& & & &\tabularnewline
\bottomrule
\end{longtable}

We can also slices strings (and lists for that matter) in intervals. So, going back to \texttt{a},

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a[::}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

slices every other character.

Strings come with several methods to manipulate them natively.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{}White Knight\textquotesingle{}}\NormalTok{.capitalize()}
\CommentTok{"It\textquotesingle{}s just a flesh wound"}\NormalTok{.count(}\StringTok{\textquotesingle{}u\textquotesingle{}}\NormalTok{)}
\CommentTok{\textquotesingle{}Almond\textquotesingle{}}\NormalTok{.endswith(}\StringTok{\textquotesingle{}nd\textquotesingle{}}\NormalTok{)}
\CommentTok{\textquotesingle{}White Knight\textquotesingle{}}\NormalTok{.lower()}
\CommentTok{\textquotesingle{}White Knight\textquotesingle{}}\NormalTok{.upper()}
\CommentTok{\textquotesingle{}flesh wound\textquotesingle{}}\NormalTok{.replace(}\StringTok{\textquotesingle{}flesh\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}bullet\textquotesingle{}}\NormalTok{)}
\CommentTok{\textquotesingle{} This is my song   \textquotesingle{}}\NormalTok{.strip()}
\CommentTok{\textquotesingle{}Hello, hello, hello\textquotesingle{}}\NormalTok{.split(}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

One of the most powerful string methods is \texttt{join}. This allows us to take a list of characters, and then
put them together using a particular separator.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{} \textquotesingle{}}\NormalTok{.join([}\StringTok{\textquotesingle{}This\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}is\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}my\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}song\textquotesingle{}}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

Also recall that we are allowed ``string arithmetic''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\textquotesingle{}g\textquotesingle{}} \OperatorTok{+} \StringTok{\textquotesingle{}a\textquotesingle{}} \OperatorTok{+} \StringTok{\textquotesingle{}f\textquotesingle{}} \OperatorTok{+} \StringTok{\textquotesingle{}f\textquotesingle{}} \OperatorTok{+} \StringTok{\textquotesingle{}e\textquotesingle{}}

\CommentTok{\textquotesingle{}a \textquotesingle{}}\OperatorTok{*}\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\hypertarget{string-formatting}{%
\subsection{String formatting}\label{string-formatting}}

In older code, you will see a formal format statement.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var }\OperatorTok{=} \StringTok{\textquotesingle{}horse\textquotesingle{}}
\NormalTok{var2 }\OperatorTok{=} \StringTok{\textquotesingle{}car\textquotesingle{}}

\NormalTok{s }\OperatorTok{=} \StringTok{\textquotesingle{}Get off my }\SpecialCharTok{\{\}}\StringTok{!\textquotesingle{}}

\NormalTok{s.}\BuiltInTok{format}\NormalTok{(var)}
\NormalTok{s.}\BuiltInTok{format}\NormalTok{(var2)}
\end{Highlighting}
\end{Shaded}

This is great for templates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{template\_string }\OperatorTok{=} \StringTok{"""}
\SpecialCharTok{\{country\}}\StringTok{, our native village}
\StringTok{There was a }\SpecialCharTok{\{species\}}\StringTok{ tree.}
\StringTok{We used to sleep under it.}
\StringTok{"""}

\BuiltInTok{print}\NormalTok{(template\_string.}\BuiltInTok{format}\NormalTok{(country}\OperatorTok{=}\StringTok{\textquotesingle{}India\textquotesingle{}}\NormalTok{, species }\OperatorTok{=} \StringTok{\textquotesingle{}banyan\textquotesingle{}}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(template\_string.}\BuiltInTok{format}\NormalTok{(country }\OperatorTok{=} \StringTok{\textquotesingle{}Canada\textquotesingle{}}\NormalTok{, species }\OperatorTok{=} \StringTok{\textquotesingle{}maple\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In Python 3.6+, the concept of \texttt{f-strings} or formatted strings was introduced. They can be easier to read, faster and have better performance.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{country }\OperatorTok{=} \StringTok{\textquotesingle{}USA\textquotesingle{}}
\SpecialStringTok{f"This is my }\SpecialCharTok{\{}\NormalTok{country}\SpecialCharTok{\}}\SpecialStringTok{!"}
\end{Highlighting}
\end{Shaded}

\hypertarget{regular-expressions}{%
\section{Regular expressions}\label{regular-expressions}}

Regular expressions are amazingly powerful tools for string search and manipulation. They are available in pretty much every
computer language in some form or the other. I'll provide a short and far from comprehensive introduction here. The website \href{https://regex101.com}{regex101.com} is a really good resource to learn and check your regular expressions.

\hypertarget{pattern-matching}{%
\subsection{Pattern matching}\label{pattern-matching}}

\begin{longtable}[]{@{}ll@{}}
\toprule
Syntax & Description\tabularnewline
\midrule
\endhead
\texttt{.} & Matches any one character\tabularnewline
\texttt{\^{}} & Matches from the beginning of a string\tabularnewline
\texttt{\$} & Matches to the end of a string\tabularnewline
\texttt{*} & Matches 0 or more repetitions of the previous character\tabularnewline
\texttt{+} & Matches 1 or more repetitions of the previous character\tabularnewline
\texttt{?} & Matches 0 or 1 repetitions of the previous character\tabularnewline
\texttt{\{m\}} & Matches \texttt{m} repetitions of the previous character\tabularnewline
\texttt{\{m,n\}} & Matches any number from \texttt{m} to \texttt{n} of the previous character\tabularnewline
\texttt{\textbackslash{}} & Escape character\tabularnewline
\texttt{{[}\ {]}} & A set of characters (e.g.~\texttt{{[}A-Z{]}} will match any capital letter)\tabularnewline
\texttt{(\ )} & Matches the pattern exactly\tabularnewline
\texttt{\textbar{}} & OR\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{biopython}{%
\chapter{BioPython}\label{biopython}}

BioPython is a package aimed at bioinformatics work. As with many Python packages, it is opinionated towards the needs of the developers, so might not meet everyone's needs.

You can install BioPython using \texttt{conda\ install\ biopython}.

We'll do a short example

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ Bio.Seq }\ImportTok{import}\NormalTok{ Seq}

\CommentTok{\#create a sequence object}
\NormalTok{my\_seq }\OperatorTok{=}\NormalTok{ Seq(}\StringTok{"CATGTAGACTAG"}\NormalTok{)}

\CommentTok{\#print out some details about it}
\BuiltInTok{print}\NormalTok{(}\StringTok{"seq }\SpecialCharTok{\%s}\StringTok{ is }\SpecialCharTok{\%i}\StringTok{ bases long"} \OperatorTok{\%}\NormalTok{ (my\_seq, }\BuiltInTok{len}\NormalTok{(my\_seq)))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"reverse complement is }\SpecialCharTok{\%s}\StringTok{"} \OperatorTok{\%}\NormalTok{ my\_seq.reverse\_complement())}
\BuiltInTok{print}\NormalTok{(}\StringTok{"protein translation is }\SpecialCharTok{\%s}\StringTok{"} \OperatorTok{\%}\NormalTok{ my\_seq.translate())}
\end{Highlighting}
\end{Shaded}

BioPython has capabilities for querying databases like \texttt{Entrez}, read sequences, do alignments using FASTA, and the like.

\end{document}
